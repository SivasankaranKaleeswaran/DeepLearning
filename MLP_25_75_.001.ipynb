{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec634a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>pickup_date</th>\n",
       "      <th>time_taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>238</td>\n",
       "      <td>239</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.47</td>\n",
       "      <td>0.3</td>\n",
       "      <td>11.27</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>4.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>239</td>\n",
       "      <td>238</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.3</td>\n",
       "      <td>12.30</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>7.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>246</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.3</td>\n",
       "      <td>17.55</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>16.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>161</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.15</td>\n",
       "      <td>0.3</td>\n",
       "      <td>24.95</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>25.283333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43</td>\n",
       "      <td>239</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.96</td>\n",
       "      <td>0.3</td>\n",
       "      <td>11.76</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>5.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6339372</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>48</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>17.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.26</td>\n",
       "      <td>0.3</td>\n",
       "      <td>25.56</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>21.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6339373</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>163</td>\n",
       "      <td>246</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.96</td>\n",
       "      <td>0.3</td>\n",
       "      <td>17.76</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>14.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6339374</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>164</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20.16</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6339375</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>12.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.3</td>\n",
       "      <td>19.56</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>16.283333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6339376</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.61</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>142</td>\n",
       "      <td>2</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>12.30</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>9.633333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4485618 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         passenger_count  trip_distance  RatecodeID  PULocationID  \\\n",
       "0                    1.0           1.20         1.0           238   \n",
       "1                    1.0           1.20         1.0           239   \n",
       "8                    2.0           2.40         1.0           246   \n",
       "10                   1.0           3.30         1.0           161   \n",
       "11                   1.0           1.07         1.0            43   \n",
       "...                  ...            ...         ...           ...   \n",
       "6339372              1.0           4.11         1.0            48   \n",
       "6339373              1.0           2.10         1.0           163   \n",
       "6339374              1.0           2.13         1.0           164   \n",
       "6339375              1.0           2.55         1.0            79   \n",
       "6339376              1.0           1.61         1.0           100   \n",
       "\n",
       "         DOLocationID  payment_type  fare_amount  extra  mta_tax  tip_amount  \\\n",
       "0                 239             1          6.0    3.0      0.5        1.47   \n",
       "1                 238             1          7.0    3.0      0.5        1.50   \n",
       "8                  79             1         12.0    3.0      0.5        1.75   \n",
       "10                144             1         17.0    3.0      0.5        4.15   \n",
       "11                239             1          6.0    0.5      0.5        1.96   \n",
       "...               ...           ...          ...    ...      ...         ...   \n",
       "6339372            75             1         17.5    0.5      0.5        4.26   \n",
       "6339373           246             1         11.0    0.5      0.5        2.96   \n",
       "6339374            79             1         13.0    0.5      0.5        3.36   \n",
       "6339375            68             1         12.5    0.5      0.5        3.26   \n",
       "6339376           142             2          8.5    0.5      0.5        0.00   \n",
       "\n",
       "         improvement_surcharge  total_amount  congestion_surcharge  \\\n",
       "0                          0.3         11.27                   2.5   \n",
       "1                          0.3         12.30                   2.5   \n",
       "8                          0.3         17.55                   2.5   \n",
       "10                         0.3         24.95                   2.5   \n",
       "11                         0.3         11.76                   2.5   \n",
       "...                        ...           ...                   ...   \n",
       "6339372                    0.3         25.56                   2.5   \n",
       "6339373                    0.3         17.76                   2.5   \n",
       "6339374                    0.3         20.16                   2.5   \n",
       "6339375                    0.3         19.56                   2.5   \n",
       "6339376                    0.3         12.30                   2.5   \n",
       "\n",
       "        pickup_date  time_taken  \n",
       "0        2020-01-01    4.800000  \n",
       "1        2020-01-01    7.416667  \n",
       "8        2020-01-01   16.866667  \n",
       "10       2020-01-01   25.283333  \n",
       "11       2020-01-01    5.616667  \n",
       "...             ...         ...  \n",
       "6339372  2020-01-31   21.500000  \n",
       "6339373  2020-01-31   14.233333  \n",
       "6339374  2020-01-31   19.000000  \n",
       "6339375  2020-01-31   16.283333  \n",
       "6339376  2020-01-31    9.633333  \n",
       "\n",
       "[4485618 rows x 15 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "df2 = pd.read_csv('updated_dataset.csv', low_memory=False)\n",
    "df2['pickup_date'] = pd.to_datetime(df2['pickup_date'], format='%Y-%m-%d')\n",
    "columns_to_remove = ['VendorID', 'store_and_fwd_flag', 'airport_fee','tpep_pickup_datetime','tpep_dropoff_datetime', 'tolls_amount']\n",
    "df2.drop(columns=columns_to_remove, inplace=True)\n",
    "df2.dropna(how='any', inplace=True)\n",
    "df2 = df2[df2['passenger_count'] != 0]\n",
    "df2 = df2[df2['trip_distance'] > 1]\n",
    "df2 = df2[df2['time_taken'] > 1]\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c22bf904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_date</th>\n",
       "      <th>tavg</th>\n",
       "      <th>tmin</th>\n",
       "      <th>tmax</th>\n",
       "      <th>wspd</th>\n",
       "      <th>pres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.3</td>\n",
       "      <td>1008.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>8.9</td>\n",
       "      <td>12.4</td>\n",
       "      <td>1013.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>7.6</td>\n",
       "      <td>6.7</td>\n",
       "      <td>8.3</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1010.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>8.2</td>\n",
       "      <td>6.7</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5.7</td>\n",
       "      <td>1003.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>4.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>7.2</td>\n",
       "      <td>8.2</td>\n",
       "      <td>1010.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>6.7</td>\n",
       "      <td>10.4</td>\n",
       "      <td>1016.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>2.6</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>6.7</td>\n",
       "      <td>13.4</td>\n",
       "      <td>1016.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-01-09</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-3.3</td>\n",
       "      <td>2.2</td>\n",
       "      <td>9.1</td>\n",
       "      <td>1038.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-01-10</td>\n",
       "      <td>6.4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>11.7</td>\n",
       "      <td>14.5</td>\n",
       "      <td>1034.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2020-01-12</td>\n",
       "      <td>15.7</td>\n",
       "      <td>9.4</td>\n",
       "      <td>19.4</td>\n",
       "      <td>15.5</td>\n",
       "      <td>1018.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2020-01-14</td>\n",
       "      <td>6.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>9.9</td>\n",
       "      <td>1025.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2020-01-15</td>\n",
       "      <td>8.2</td>\n",
       "      <td>6.1</td>\n",
       "      <td>11.7</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1020.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2020-01-16</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>1015.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2020-01-17</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>-3.9</td>\n",
       "      <td>2.2</td>\n",
       "      <td>8.8</td>\n",
       "      <td>1034.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2020-01-18</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>10.2</td>\n",
       "      <td>1028.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2020-01-19</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>7.2</td>\n",
       "      <td>10.2</td>\n",
       "      <td>1008.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2020-01-20</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>9.1</td>\n",
       "      <td>1024.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2020-01-21</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>-4.4</td>\n",
       "      <td>3.3</td>\n",
       "      <td>8.9</td>\n",
       "      <td>1030.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>5.6</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1031.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1029.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.3</td>\n",
       "      <td>11.7</td>\n",
       "      <td>10.6</td>\n",
       "      <td>1027.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2020-01-25</td>\n",
       "      <td>6.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>22.9</td>\n",
       "      <td>1014.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2020-01-26</td>\n",
       "      <td>5.5</td>\n",
       "      <td>3.3</td>\n",
       "      <td>8.9</td>\n",
       "      <td>14.9</td>\n",
       "      <td>1009.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2020-01-28</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.9</td>\n",
       "      <td>7.2</td>\n",
       "      <td>6.3</td>\n",
       "      <td>1010.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2020-01-29</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>7.2</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1018.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2020-01-30</td>\n",
       "      <td>1.3</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>10.7</td>\n",
       "      <td>1026.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.1</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1026.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pickup_date  tavg  tmin  tmax  wspd    pres\n",
       "0   2020-01-01   3.6   1.7   5.0  17.3  1008.2\n",
       "1   2020-01-02   4.7   0.6   8.9  12.4  1013.9\n",
       "2   2020-01-03   7.6   6.7   8.3   8.4  1010.2\n",
       "3   2020-01-04   8.2   6.7   9.4   5.7  1003.7\n",
       "4   2020-01-05   4.6   2.8   7.2   8.2  1010.1\n",
       "6   2020-01-07   4.7   3.3   6.7  10.4  1016.2\n",
       "7   2020-01-08   2.6  -0.6   6.7  13.4  1016.6\n",
       "8   2020-01-09  -0.6  -3.3   2.2   9.1  1038.8\n",
       "9   2020-01-10   6.4   1.1  11.7  14.5  1034.5\n",
       "11  2020-01-12  15.7   9.4  19.4  15.5  1018.1\n",
       "13  2020-01-14   6.3   5.0   7.8   9.9  1025.3\n",
       "14  2020-01-15   8.2   6.1  11.7   9.0  1020.9\n",
       "15  2020-01-16   6.7   2.2  10.0  10.6  1015.1\n",
       "16  2020-01-17  -1.2  -3.9   2.2   8.8  1034.7\n",
       "17  2020-01-18  -2.2  -5.0   2.8  10.2  1028.5\n",
       "18  2020-01-19   4.0   0.6   7.2  10.2  1008.9\n",
       "19  2020-01-20  -1.7  -5.0   2.8   9.1  1024.2\n",
       "20  2020-01-21  -1.5  -4.4   3.3   8.9  1030.8\n",
       "21  2020-01-22   1.0  -2.2   5.6   8.1  1031.3\n",
       "22  2020-01-23   3.5   0.0   7.2   7.5  1029.4\n",
       "23  2020-01-24   6.5   3.3  11.7  10.6  1027.4\n",
       "24  2020-01-25   6.6   4.4  10.0  22.9  1014.5\n",
       "25  2020-01-26   5.5   3.3   8.9  14.9  1009.3\n",
       "27  2020-01-28   4.9   3.9   7.2   6.3  1010.2\n",
       "28  2020-01-29   3.5   1.1   7.2   7.8  1018.2\n",
       "29  2020-01-30   1.3  -1.7   4.4  10.7  1026.3\n",
       "30  2020-01-31   4.3   2.2   6.1   7.5  1026.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_excel('weather.xlsx')\n",
    "df1['pickup_date'] = pd.to_datetime(df1['pickup_date'], format='%Y-%m-%d')\n",
    "\n",
    "columns_to_remove = ['prcp', 'snow', 'wdir','wpgt', 'tsun']\n",
    "df1.drop(columns=columns_to_remove, inplace=True)\n",
    "df1.dropna(how='any', inplace=True)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92f1a9d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>pickup_date</th>\n",
       "      <th>time_taken</th>\n",
       "      <th>tavg</th>\n",
       "      <th>tmin</th>\n",
       "      <th>tmax</th>\n",
       "      <th>wspd</th>\n",
       "      <th>pres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>238</td>\n",
       "      <td>239</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.47</td>\n",
       "      <td>0.3</td>\n",
       "      <td>11.27</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.3</td>\n",
       "      <td>1008.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>239</td>\n",
       "      <td>238</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.3</td>\n",
       "      <td>12.30</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>7.416667</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.3</td>\n",
       "      <td>1008.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>246</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.3</td>\n",
       "      <td>17.55</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>16.866667</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.3</td>\n",
       "      <td>1008.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>161</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.15</td>\n",
       "      <td>0.3</td>\n",
       "      <td>24.95</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>25.283333</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.3</td>\n",
       "      <td>1008.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43</td>\n",
       "      <td>239</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.96</td>\n",
       "      <td>0.3</td>\n",
       "      <td>11.76</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>5.616667</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.3</td>\n",
       "      <td>1008.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4485613</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>48</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>17.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.26</td>\n",
       "      <td>0.3</td>\n",
       "      <td>25.56</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.1</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1026.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4485614</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>163</td>\n",
       "      <td>246</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.96</td>\n",
       "      <td>0.3</td>\n",
       "      <td>17.76</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>14.233333</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.1</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1026.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4485615</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>164</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20.16</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.1</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1026.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4485616</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>12.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.3</td>\n",
       "      <td>19.56</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>16.283333</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.1</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1026.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4485617</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.61</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>142</td>\n",
       "      <td>2</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>12.30</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>9.633333</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.1</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1026.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4485618 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         passenger_count  trip_distance  RatecodeID  PULocationID  \\\n",
       "0                    1.0           1.20         1.0           238   \n",
       "1                    1.0           1.20         1.0           239   \n",
       "2                    2.0           2.40         1.0           246   \n",
       "3                    1.0           3.30         1.0           161   \n",
       "4                    1.0           1.07         1.0            43   \n",
       "...                  ...            ...         ...           ...   \n",
       "4485613              1.0           4.11         1.0            48   \n",
       "4485614              1.0           2.10         1.0           163   \n",
       "4485615              1.0           2.13         1.0           164   \n",
       "4485616              1.0           2.55         1.0            79   \n",
       "4485617              1.0           1.61         1.0           100   \n",
       "\n",
       "         DOLocationID  payment_type  fare_amount  extra  mta_tax  tip_amount  \\\n",
       "0                 239             1          6.0    3.0      0.5        1.47   \n",
       "1                 238             1          7.0    3.0      0.5        1.50   \n",
       "2                  79             1         12.0    3.0      0.5        1.75   \n",
       "3                 144             1         17.0    3.0      0.5        4.15   \n",
       "4                 239             1          6.0    0.5      0.5        1.96   \n",
       "...               ...           ...          ...    ...      ...         ...   \n",
       "4485613            75             1         17.5    0.5      0.5        4.26   \n",
       "4485614           246             1         11.0    0.5      0.5        2.96   \n",
       "4485615            79             1         13.0    0.5      0.5        3.36   \n",
       "4485616            68             1         12.5    0.5      0.5        3.26   \n",
       "4485617           142             2          8.5    0.5      0.5        0.00   \n",
       "\n",
       "         improvement_surcharge  total_amount  congestion_surcharge  \\\n",
       "0                          0.3         11.27                   2.5   \n",
       "1                          0.3         12.30                   2.5   \n",
       "2                          0.3         17.55                   2.5   \n",
       "3                          0.3         24.95                   2.5   \n",
       "4                          0.3         11.76                   2.5   \n",
       "...                        ...           ...                   ...   \n",
       "4485613                    0.3         25.56                   2.5   \n",
       "4485614                    0.3         17.76                   2.5   \n",
       "4485615                    0.3         20.16                   2.5   \n",
       "4485616                    0.3         19.56                   2.5   \n",
       "4485617                    0.3         12.30                   2.5   \n",
       "\n",
       "        pickup_date  time_taken  tavg  tmin  tmax  wspd    pres  \n",
       "0        2020-01-01    4.800000   3.6   1.7   5.0  17.3  1008.2  \n",
       "1        2020-01-01    7.416667   3.6   1.7   5.0  17.3  1008.2  \n",
       "2        2020-01-01   16.866667   3.6   1.7   5.0  17.3  1008.2  \n",
       "3        2020-01-01   25.283333   3.6   1.7   5.0  17.3  1008.2  \n",
       "4        2020-01-01    5.616667   3.6   1.7   5.0  17.3  1008.2  \n",
       "...             ...         ...   ...   ...   ...   ...     ...  \n",
       "4485613  2020-01-31   21.500000   4.3   2.2   6.1   7.5  1026.0  \n",
       "4485614  2020-01-31   14.233333   4.3   2.2   6.1   7.5  1026.0  \n",
       "4485615  2020-01-31   19.000000   4.3   2.2   6.1   7.5  1026.0  \n",
       "4485616  2020-01-31   16.283333   4.3   2.2   6.1   7.5  1026.0  \n",
       "4485617  2020-01-31    9.633333   4.3   2.2   6.1   7.5  1026.0  \n",
       "\n",
       "[4485618 rows x 20 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = df2.merge(df1, left_on='pickup_date', right_on='pickup_date', how='left')\n",
    "\n",
    "columns_to_populate = ['tavg', 'tmin', 'tmax', 'wspd']\n",
    "for col in columns_to_populate:\n",
    "    merged_df[col].fillna(merged_df[f'{col}'], inplace=True)\n",
    "#merged_df=merged_df[merged_df['pickup_date'].dt.day<=10]\n",
    "#merged_df = merged_df[merged_df['tavg'] > 0]\n",
    "#merged_df = merged_df[merged_df['wspd'] > 0]\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d4afdfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['trip_distance','PULocationID', 'DOLocationID', 'time_taken', 'tavg', 'pres']\n",
    "\n",
    "new_df = merged_df[selected_columns]\n",
    "#new_df=new_df[new_df['PULocationID'].isin([132, 161, 237, 236, 186, 162, 230, 142, 48])]\n",
    "#new_df=new_df[new_df['DOLocationID'].isin([236,237,161,239,142, 238, 162])]\n",
    "new_df = new_df.dropna(subset=['tavg', 'pres'])\n",
    "new_df = new_df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c3310bd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data - X_train shape: (1566329, 5) y_train shape: (1566329,)\n",
      "Testing data - X_test shape: (391583, 5) y_test shape: (391583,)\n",
      "         trip_distance  PULocationID  DOLocationID  time_taken  tavg    pres\n",
      "2                 1.20            48           233   12.200000   7.6  1010.2\n",
      "3                 5.20            88           162   18.183333   4.9  1010.2\n",
      "4                 1.05           114            90   10.266667   5.5  1009.3\n",
      "5                 2.16            79           161   15.950000   6.7  1015.1\n",
      "6                 1.50           170           107   12.350000  -2.2  1028.5\n",
      "...                ...           ...           ...         ...   ...     ...\n",
      "3923012           5.10           246           166   16.333333   4.9  1010.2\n",
      "3923016           3.49           262           152   15.550000   4.3  1026.0\n",
      "3923017           3.77            97            36   18.400000  -2.2  1028.5\n",
      "3923022           3.24           161           145   15.100000  -0.6  1038.8\n",
      "3923028           1.42           140           163   11.500000  -1.7  1024.2\n",
      "\n",
      "[1957912 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "p_25 = new_df['time_taken'].quantile(0.25)\n",
    "p_75 = new_df['time_taken'].quantile(0.75)\n",
    "new_df = new_df[(new_df['time_taken'] > p_27) & (new_df['time_taken'] < p_72)]\n",
    "#new_df.sort_values('DOLocationID', ascending=False, inplace=True)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = new_df.drop(columns=['time_taken'])\n",
    "y = new_df['time_taken']  \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training data - X_train shape:\", X_train.shape, \"y_train shape:\", y_train.shape)\n",
    "print(\"Testing data - X_test shape:\", X_test.shape, \"y_test shape:\", y_test.shape)\n",
    "print(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "899ea7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "48948/48948 [==============================] - 124s 3ms/step - loss: 6.2443 - mean_absolute_error: 2.0476 - val_loss: 6.0748 - val_mean_absolute_error: 2.0218\n",
      "Epoch 2/100\n",
      "48948/48948 [==============================] - 122s 3ms/step - loss: 6.0651 - mean_absolute_error: 2.0254 - val_loss: 6.0205 - val_mean_absolute_error: 2.0114\n",
      "Epoch 3/100\n",
      "48948/48948 [==============================] - 128s 3ms/step - loss: 6.0439 - mean_absolute_error: 2.0215 - val_loss: 6.0273 - val_mean_absolute_error: 2.0132\n",
      "Epoch 4/100\n",
      "48948/48948 [==============================] - 116s 2ms/step - loss: 6.0287 - mean_absolute_error: 2.0187 - val_loss: 6.0113 - val_mean_absolute_error: 2.0181\n",
      "Epoch 5/100\n",
      "48948/48948 [==============================] - 123s 3ms/step - loss: 6.0165 - mean_absolute_error: 2.0162 - val_loss: 6.0811 - val_mean_absolute_error: 2.0396\n",
      "Epoch 6/100\n",
      "48948/48948 [==============================] - 117s 2ms/step - loss: 6.0045 - mean_absolute_error: 2.0142 - val_loss: 5.9773 - val_mean_absolute_error: 2.0155\n",
      "Epoch 7/100\n",
      "48948/48948 [==============================] - 128s 3ms/step - loss: 5.9929 - mean_absolute_error: 2.0122 - val_loss: 6.0379 - val_mean_absolute_error: 2.0337\n",
      "Epoch 8/100\n",
      "48948/48948 [==============================] - 153s 3ms/step - loss: 5.9811 - mean_absolute_error: 2.0101 - val_loss: 5.9781 - val_mean_absolute_error: 2.0099\n",
      "Epoch 9/100\n",
      "48948/48948 [==============================] - 144s 3ms/step - loss: 5.9711 - mean_absolute_error: 2.0083 - val_loss: 5.9498 - val_mean_absolute_error: 2.0059\n",
      "Epoch 10/100\n",
      "48948/48948 [==============================] - 148s 3ms/step - loss: 5.9617 - mean_absolute_error: 2.0064 - val_loss: 5.9627 - val_mean_absolute_error: 1.9994\n",
      "Epoch 11/100\n",
      "48948/48948 [==============================] - 154s 3ms/step - loss: 5.9515 - mean_absolute_error: 2.0044 - val_loss: 5.9528 - val_mean_absolute_error: 2.0040\n",
      "Epoch 12/100\n",
      "48948/48948 [==============================] - 149s 3ms/step - loss: 5.9417 - mean_absolute_error: 2.0026 - val_loss: 5.9297 - val_mean_absolute_error: 1.9999\n",
      "Epoch 13/100\n",
      "48948/48948 [==============================] - 133s 3ms/step - loss: 5.9335 - mean_absolute_error: 2.0011 - val_loss: 5.9117 - val_mean_absolute_error: 2.0000\n",
      "Epoch 14/100\n",
      "48948/48948 [==============================] - 117s 2ms/step - loss: 5.9235 - mean_absolute_error: 1.9989 - val_loss: 5.9097 - val_mean_absolute_error: 1.9995\n",
      "Epoch 15/100\n",
      "48948/48948 [==============================] - 120s 2ms/step - loss: 5.9134 - mean_absolute_error: 1.9970 - val_loss: 5.9030 - val_mean_absolute_error: 2.0068\n",
      "Epoch 16/100\n",
      "48948/48948 [==============================] - 122s 2ms/step - loss: 5.9051 - mean_absolute_error: 1.9953 - val_loss: 5.8954 - val_mean_absolute_error: 1.9987\n",
      "Epoch 17/100\n",
      "48948/48948 [==============================] - 118s 2ms/step - loss: 5.8949 - mean_absolute_error: 1.9931 - val_loss: 5.9103 - val_mean_absolute_error: 2.0101\n",
      "Epoch 18/100\n",
      "48948/48948 [==============================] - 126s 3ms/step - loss: 5.8857 - mean_absolute_error: 1.9912 - val_loss: 5.8846 - val_mean_absolute_error: 1.9984\n",
      "Epoch 19/100\n",
      "48948/48948 [==============================] - 117s 2ms/step - loss: 5.8774 - mean_absolute_error: 1.9895 - val_loss: 5.8665 - val_mean_absolute_error: 1.9898\n",
      "Epoch 20/100\n",
      "48948/48948 [==============================] - 126s 3ms/step - loss: 5.8692 - mean_absolute_error: 1.9878 - val_loss: 5.9039 - val_mean_absolute_error: 2.0035\n",
      "Epoch 21/100\n",
      "48948/48948 [==============================] - 117s 2ms/step - loss: 5.8606 - mean_absolute_error: 1.9861 - val_loss: 5.8629 - val_mean_absolute_error: 1.9809\n",
      "Epoch 22/100\n",
      "48948/48948 [==============================] - 124s 3ms/step - loss: 5.8532 - mean_absolute_error: 1.9846 - val_loss: 5.8497 - val_mean_absolute_error: 1.9864\n",
      "Epoch 23/100\n",
      "48948/48948 [==============================] - 115s 2ms/step - loss: 5.8444 - mean_absolute_error: 1.9827 - val_loss: 5.8562 - val_mean_absolute_error: 1.9974\n",
      "Epoch 24/100\n",
      "48948/48948 [==============================] - 123s 3ms/step - loss: 5.8372 - mean_absolute_error: 1.9812 - val_loss: 5.8387 - val_mean_absolute_error: 1.9695\n",
      "Epoch 25/100\n",
      "48948/48948 [==============================] - 115s 2ms/step - loss: 5.8299 - mean_absolute_error: 1.9796 - val_loss: 5.8458 - val_mean_absolute_error: 1.9924\n",
      "Epoch 26/100\n",
      "48948/48948 [==============================] - 124s 3ms/step - loss: 5.8240 - mean_absolute_error: 1.9785 - val_loss: 5.8208 - val_mean_absolute_error: 1.9800\n",
      "Epoch 27/100\n",
      "48948/48948 [==============================] - 117s 2ms/step - loss: 5.8168 - mean_absolute_error: 1.9770 - val_loss: 5.8452 - val_mean_absolute_error: 1.9750\n",
      "Epoch 28/100\n",
      "48948/48948 [==============================] - 125s 3ms/step - loss: 5.8102 - mean_absolute_error: 1.9755 - val_loss: 5.8136 - val_mean_absolute_error: 1.9872\n",
      "Epoch 29/100\n",
      "48948/48948 [==============================] - 117s 2ms/step - loss: 5.8054 - mean_absolute_error: 1.9746 - val_loss: 5.8364 - val_mean_absolute_error: 1.9948\n",
      "Epoch 30/100\n",
      "48948/48948 [==============================] - 125s 3ms/step - loss: 5.8000 - mean_absolute_error: 1.9733 - val_loss: 5.7956 - val_mean_absolute_error: 1.9731\n",
      "Epoch 31/100\n",
      "48948/48948 [==============================] - 119s 2ms/step - loss: 5.7943 - mean_absolute_error: 1.9722 - val_loss: 5.7893 - val_mean_absolute_error: 1.9650\n",
      "Epoch 32/100\n",
      "48948/48948 [==============================] - 129s 3ms/step - loss: 5.7896 - mean_absolute_error: 1.9713 - val_loss: 5.7930 - val_mean_absolute_error: 1.9641\n",
      "Epoch 33/100\n",
      "48948/48948 [==============================] - 120s 2ms/step - loss: 5.7847 - mean_absolute_error: 1.9702 - val_loss: 5.7865 - val_mean_absolute_error: 1.9721\n",
      "Epoch 34/100\n",
      "48948/48948 [==============================] - 118s 2ms/step - loss: 5.7796 - mean_absolute_error: 1.9690 - val_loss: 5.7767 - val_mean_absolute_error: 1.9818\n",
      "Epoch 35/100\n",
      "48948/48948 [==============================] - 124s 3ms/step - loss: 5.7746 - mean_absolute_error: 1.9681 - val_loss: 5.7529 - val_mean_absolute_error: 1.9640\n",
      "Epoch 36/100\n",
      "48948/48948 [==============================] - 116s 2ms/step - loss: 5.7704 - mean_absolute_error: 1.9674 - val_loss: 5.7696 - val_mean_absolute_error: 1.9743\n",
      "Epoch 37/100\n",
      "48948/48948 [==============================] - 123s 3ms/step - loss: 5.7657 - mean_absolute_error: 1.9662 - val_loss: 5.7660 - val_mean_absolute_error: 1.9745\n",
      "Epoch 38/100\n",
      "48948/48948 [==============================] - 117s 2ms/step - loss: 5.7616 - mean_absolute_error: 1.9652 - val_loss: 5.7709 - val_mean_absolute_error: 1.9594\n",
      "Epoch 39/100\n",
      "48948/48948 [==============================] - 122s 2ms/step - loss: 5.7574 - mean_absolute_error: 1.9646 - val_loss: 5.7535 - val_mean_absolute_error: 1.9653\n",
      "Epoch 40/100\n",
      "48948/48948 [==============================] - 116s 2ms/step - loss: 5.7527 - mean_absolute_error: 1.9635 - val_loss: 5.7707 - val_mean_absolute_error: 1.9667\n",
      "Epoch 41/100\n",
      "48948/48948 [==============================] - 125s 3ms/step - loss: 5.7489 - mean_absolute_error: 1.9628 - val_loss: 5.7731 - val_mean_absolute_error: 1.9617\n",
      "Epoch 42/100\n",
      "48948/48948 [==============================] - 116s 2ms/step - loss: 5.7459 - mean_absolute_error: 1.9621 - val_loss: 5.7535 - val_mean_absolute_error: 1.9759\n",
      "Epoch 43/100\n",
      "48948/48948 [==============================] - 125s 3ms/step - loss: 5.7415 - mean_absolute_error: 1.9614 - val_loss: 5.7624 - val_mean_absolute_error: 1.9772\n",
      "Epoch 44/100\n",
      "48948/48948 [==============================] - 116s 2ms/step - loss: 5.7380 - mean_absolute_error: 1.9605 - val_loss: 5.7532 - val_mean_absolute_error: 1.9720\n",
      "Epoch 45/100\n",
      "48948/48948 [==============================] - 124s 3ms/step - loss: 5.7345 - mean_absolute_error: 1.9600 - val_loss: 5.7712 - val_mean_absolute_error: 1.9806\n",
      "Epoch 45: early stopping\n",
      "12237/12237 [==============================] - 17s 1ms/step - loss: 5.7712 - mean_absolute_error: 1.9806\n",
      "Optimizer: SGD\n",
      "Mean Squared Error on Test Data: 5.77\n",
      "Mean Absolute Error on Test Data: 1.98\n",
      "Training stopped early at epoch 44 to prevent overfitting.\n",
      "Epoch 1/100\n",
      "48948/48948 [==============================] - 136s 3ms/step - loss: 6.2917 - mean_absolute_error: 2.0570 - val_loss: 6.0666 - val_mean_absolute_error: 2.0285\n",
      "Epoch 2/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48948/48948 [==============================] - 140s 3ms/step - loss: 6.0979 - mean_absolute_error: 2.0303 - val_loss: 6.1300 - val_mean_absolute_error: 2.0083\n",
      "Epoch 3/100\n",
      "48948/48948 [==============================] - 145s 3ms/step - loss: 6.0615 - mean_absolute_error: 2.0245 - val_loss: 6.0723 - val_mean_absolute_error: 2.0244\n",
      "Epoch 4/100\n",
      "48948/48948 [==============================] - 137s 3ms/step - loss: 6.0376 - mean_absolute_error: 2.0210 - val_loss: 6.0230 - val_mean_absolute_error: 2.0167\n",
      "Epoch 5/100\n",
      "48948/48948 [==============================] - 146s 3ms/step - loss: 6.0121 - mean_absolute_error: 2.0161 - val_loss: 5.9997 - val_mean_absolute_error: 2.0147\n",
      "Epoch 6/100\n",
      "48948/48948 [==============================] - 138s 3ms/step - loss: 5.9972 - mean_absolute_error: 2.0133 - val_loss: 5.9886 - val_mean_absolute_error: 2.0205\n",
      "Epoch 7/100\n",
      "48948/48948 [==============================] - 148s 3ms/step - loss: 5.9868 - mean_absolute_error: 2.0113 - val_loss: 6.0112 - val_mean_absolute_error: 2.0291\n",
      "Epoch 8/100\n",
      "48948/48948 [==============================] - 136s 3ms/step - loss: 5.9795 - mean_absolute_error: 2.0098 - val_loss: 6.0444 - val_mean_absolute_error: 2.0205\n",
      "Epoch 9/100\n",
      "48948/48948 [==============================] - 139s 3ms/step - loss: 5.9726 - mean_absolute_error: 2.0084 - val_loss: 5.9621 - val_mean_absolute_error: 2.0019\n",
      "Epoch 10/100\n",
      "48948/48948 [==============================] - 146s 3ms/step - loss: 5.9664 - mean_absolute_error: 2.0071 - val_loss: 5.9641 - val_mean_absolute_error: 1.9972\n",
      "Epoch 11/100\n",
      "48948/48948 [==============================] - 135s 3ms/step - loss: 5.9593 - mean_absolute_error: 2.0057 - val_loss: 6.0158 - val_mean_absolute_error: 2.0065\n",
      "Epoch 12/100\n",
      "48948/48948 [==============================] - 145s 3ms/step - loss: 5.9506 - mean_absolute_error: 2.0039 - val_loss: 5.9584 - val_mean_absolute_error: 1.9956\n",
      "Epoch 13/100\n",
      "48948/48948 [==============================] - 137s 3ms/step - loss: 5.9420 - mean_absolute_error: 2.0023 - val_loss: 5.9518 - val_mean_absolute_error: 2.0109\n",
      "Epoch 14/100\n",
      "48948/48948 [==============================] - 147s 3ms/step - loss: 5.9358 - mean_absolute_error: 2.0009 - val_loss: 5.9324 - val_mean_absolute_error: 1.9996\n",
      "Epoch 15/100\n",
      "48948/48948 [==============================] - 136s 3ms/step - loss: 5.9307 - mean_absolute_error: 1.9999 - val_loss: 5.9364 - val_mean_absolute_error: 2.0058\n",
      "Epoch 16/100\n",
      "48948/48948 [==============================] - 138s 3ms/step - loss: 5.9247 - mean_absolute_error: 1.9985 - val_loss: 5.9151 - val_mean_absolute_error: 1.9989\n",
      "Epoch 17/100\n",
      "48948/48948 [==============================] - 145s 3ms/step - loss: 5.9189 - mean_absolute_error: 1.9973 - val_loss: 5.9273 - val_mean_absolute_error: 2.0092\n",
      "Epoch 18/100\n",
      "48948/48948 [==============================] - 137s 3ms/step - loss: 5.9141 - mean_absolute_error: 1.9963 - val_loss: 5.9020 - val_mean_absolute_error: 2.0018\n",
      "Epoch 19/100\n",
      "48948/48948 [==============================] - 147s 3ms/step - loss: 5.9051 - mean_absolute_error: 1.9946 - val_loss: 5.8968 - val_mean_absolute_error: 2.0033\n",
      "Epoch 20/100\n",
      "48948/48948 [==============================] - 138s 3ms/step - loss: 5.9003 - mean_absolute_error: 1.9937 - val_loss: 5.8904 - val_mean_absolute_error: 1.9956\n",
      "Epoch 21/100\n",
      "48948/48948 [==============================] - 148s 3ms/step - loss: 5.8958 - mean_absolute_error: 1.9928 - val_loss: 5.8853 - val_mean_absolute_error: 1.9951\n",
      "Epoch 22/100\n",
      "48948/48948 [==============================] - 138s 3ms/step - loss: 5.8911 - mean_absolute_error: 1.9919 - val_loss: 5.8999 - val_mean_absolute_error: 1.9897\n",
      "Epoch 23/100\n",
      "48948/48948 [==============================] - 139s 3ms/step - loss: 5.8872 - mean_absolute_error: 1.9910 - val_loss: 5.8880 - val_mean_absolute_error: 1.9952\n",
      "Epoch 24/100\n",
      "48948/48948 [==============================] - 148s 3ms/step - loss: 5.8824 - mean_absolute_error: 1.9903 - val_loss: 5.8738 - val_mean_absolute_error: 1.9865\n",
      "Epoch 25/100\n",
      "48948/48948 [==============================] - 146s 3ms/step - loss: 5.8774 - mean_absolute_error: 1.9892 - val_loss: 5.8808 - val_mean_absolute_error: 1.9980\n",
      "Epoch 26/100\n",
      "48948/48948 [==============================] - 155s 3ms/step - loss: 5.8746 - mean_absolute_error: 1.9885 - val_loss: 5.8610 - val_mean_absolute_error: 1.9937\n",
      "Epoch 27/100\n",
      "48948/48948 [==============================] - 139s 3ms/step - loss: 5.8716 - mean_absolute_error: 1.9879 - val_loss: 5.8695 - val_mean_absolute_error: 1.9903\n",
      "Epoch 28/100\n",
      "48948/48948 [==============================] - 144s 3ms/step - loss: 5.8694 - mean_absolute_error: 1.9876 - val_loss: 5.8854 - val_mean_absolute_error: 1.9810\n",
      "Epoch 29/100\n",
      "48948/48948 [==============================] - 141s 3ms/step - loss: 5.8654 - mean_absolute_error: 1.9866 - val_loss: 5.8624 - val_mean_absolute_error: 1.9868\n",
      "Epoch 30/100\n",
      "48948/48948 [==============================] - 135s 3ms/step - loss: 5.8621 - mean_absolute_error: 1.9861 - val_loss: 5.8720 - val_mean_absolute_error: 1.9957\n",
      "Epoch 31/100\n",
      "48948/48948 [==============================] - 146s 3ms/step - loss: 5.8589 - mean_absolute_error: 1.9852 - val_loss: 5.8681 - val_mean_absolute_error: 1.9981\n",
      "Epoch 32/100\n",
      "48948/48948 [==============================] - 135s 3ms/step - loss: 5.8574 - mean_absolute_error: 1.9851 - val_loss: 5.8674 - val_mean_absolute_error: 1.9973\n",
      "Epoch 33/100\n",
      "48948/48948 [==============================] - 143s 3ms/step - loss: 5.8560 - mean_absolute_error: 1.9849 - val_loss: 5.8608 - val_mean_absolute_error: 1.9860\n",
      "Epoch 34/100\n",
      "48948/48948 [==============================] - 138s 3ms/step - loss: 5.8541 - mean_absolute_error: 1.9843 - val_loss: 5.8525 - val_mean_absolute_error: 1.9849\n",
      "Epoch 35/100\n",
      "48948/48948 [==============================] - 144s 3ms/step - loss: 5.8514 - mean_absolute_error: 1.9839 - val_loss: 5.8454 - val_mean_absolute_error: 1.9820\n",
      "Epoch 36/100\n",
      "48948/48948 [==============================] - 143s 3ms/step - loss: 5.8497 - mean_absolute_error: 1.9835 - val_loss: 5.8554 - val_mean_absolute_error: 1.9814\n",
      "Epoch 37/100\n",
      "48948/48948 [==============================] - 137s 3ms/step - loss: 5.8462 - mean_absolute_error: 1.9828 - val_loss: 5.8467 - val_mean_absolute_error: 1.9926\n",
      "Epoch 38/100\n",
      "48948/48948 [==============================] - 146s 3ms/step - loss: 5.8446 - mean_absolute_error: 1.9825 - val_loss: 5.8302 - val_mean_absolute_error: 1.9824\n",
      "Epoch 39/100\n",
      "48948/48948 [==============================] - 137s 3ms/step - loss: 5.8425 - mean_absolute_error: 1.9820 - val_loss: 5.8578 - val_mean_absolute_error: 1.9817\n",
      "Epoch 40/100\n",
      "48948/48948 [==============================] - 145s 3ms/step - loss: 5.8411 - mean_absolute_error: 1.9818 - val_loss: 5.8387 - val_mean_absolute_error: 1.9773\n",
      "Epoch 41/100\n",
      "48948/48948 [==============================] - 135s 3ms/step - loss: 5.8380 - mean_absolute_error: 1.9813 - val_loss: 5.8658 - val_mean_absolute_error: 1.9817\n",
      "Epoch 42/100\n",
      "48948/48948 [==============================] - 141s 3ms/step - loss: 5.8354 - mean_absolute_error: 1.9807 - val_loss: 5.8370 - val_mean_absolute_error: 1.9720\n",
      "Epoch 43/100\n",
      "48948/48948 [==============================] - 144s 3ms/step - loss: 5.8351 - mean_absolute_error: 1.9805 - val_loss: 5.8246 - val_mean_absolute_error: 1.9865\n",
      "Epoch 44/100\n",
      "48948/48948 [==============================] - 137s 3ms/step - loss: 5.8305 - mean_absolute_error: 1.9796 - val_loss: 5.8482 - val_mean_absolute_error: 1.9849\n",
      "Epoch 45/100\n",
      "48948/48948 [==============================] - 150s 3ms/step - loss: 5.8290 - mean_absolute_error: 1.9793 - val_loss: 5.8293 - val_mean_absolute_error: 1.9836\n",
      "Epoch 46/100\n",
      "48948/48948 [==============================] - 155s 3ms/step - loss: 5.8261 - mean_absolute_error: 1.9787 - val_loss: 5.8354 - val_mean_absolute_error: 1.9807\n",
      "Epoch 47/100\n",
      "48948/48948 [==============================] - 167s 3ms/step - loss: 5.8264 - mean_absolute_error: 1.9788 - val_loss: 5.8365 - val_mean_absolute_error: 1.9909\n",
      "Epoch 48/100\n",
      "48948/48948 [==============================] - 150s 3ms/step - loss: 5.8242 - mean_absolute_error: 1.9784 - val_loss: 5.8668 - val_mean_absolute_error: 1.9953\n",
      "Epoch 49/100\n",
      "48948/48948 [==============================] - 153s 3ms/step - loss: 5.8221 - mean_absolute_error: 1.9779 - val_loss: 5.8253 - val_mean_absolute_error: 1.9827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100\n",
      "48948/48948 [==============================] - 178s 4ms/step - loss: 5.8205 - mean_absolute_error: 1.9777 - val_loss: 5.8181 - val_mean_absolute_error: 1.9767\n",
      "Epoch 51/100\n",
      "48948/48948 [==============================] - 160s 3ms/step - loss: 5.8196 - mean_absolute_error: 1.9774 - val_loss: 5.8066 - val_mean_absolute_error: 1.9836\n",
      "Epoch 52/100\n",
      "48948/48948 [==============================] - 160s 3ms/step - loss: 5.8180 - mean_absolute_error: 1.9771 - val_loss: 5.8273 - val_mean_absolute_error: 1.9819\n",
      "Epoch 53/100\n",
      "48948/48948 [==============================] - 141s 3ms/step - loss: 5.8164 - mean_absolute_error: 1.9768 - val_loss: 5.8240 - val_mean_absolute_error: 1.9752\n",
      "Epoch 54/100\n",
      "48948/48948 [==============================] - 152s 3ms/step - loss: 5.8161 - mean_absolute_error: 1.9769 - val_loss: 5.8143 - val_mean_absolute_error: 1.9776\n",
      "Epoch 55/100\n",
      "48948/48948 [==============================] - 175s 4ms/step - loss: 5.8134 - mean_absolute_error: 1.9761 - val_loss: 5.8247 - val_mean_absolute_error: 1.9789\n",
      "Epoch 56/100\n",
      "48948/48948 [==============================] - 154s 3ms/step - loss: 5.8103 - mean_absolute_error: 1.9756 - val_loss: 5.8197 - val_mean_absolute_error: 1.9798\n",
      "Epoch 57/100\n",
      "48948/48948 [==============================] - 169s 3ms/step - loss: 5.8095 - mean_absolute_error: 1.9754 - val_loss: 5.8002 - val_mean_absolute_error: 1.9727\n",
      "Epoch 58/100\n",
      "48948/48948 [==============================] - 154s 3ms/step - loss: 5.8107 - mean_absolute_error: 1.9755 - val_loss: 5.8034 - val_mean_absolute_error: 1.9795\n",
      "Epoch 59/100\n",
      "48948/48948 [==============================] - 148s 3ms/step - loss: 5.8086 - mean_absolute_error: 1.9753 - val_loss: 5.7973 - val_mean_absolute_error: 1.9765\n",
      "Epoch 60/100\n",
      "48948/48948 [==============================] - 157s 3ms/step - loss: 5.8076 - mean_absolute_error: 1.9751 - val_loss: 5.8044 - val_mean_absolute_error: 1.9790\n",
      "Epoch 61/100\n",
      "48948/48948 [==============================] - 145s 3ms/step - loss: 5.8069 - mean_absolute_error: 1.9750 - val_loss: 5.8190 - val_mean_absolute_error: 1.9702\n",
      "Epoch 62/100\n",
      "48948/48948 [==============================] - 154s 3ms/step - loss: 5.8068 - mean_absolute_error: 1.9750 - val_loss: 5.8054 - val_mean_absolute_error: 1.9718\n",
      "Epoch 63/100\n",
      "48948/48948 [==============================] - 160s 3ms/step - loss: 5.8044 - mean_absolute_error: 1.9745 - val_loss: 5.7915 - val_mean_absolute_error: 1.9725\n",
      "Epoch 64/100\n",
      "48948/48948 [==============================] - 170s 3ms/step - loss: 5.8055 - mean_absolute_error: 1.9747 - val_loss: 5.8005 - val_mean_absolute_error: 1.9715\n",
      "Epoch 65/100\n",
      "48948/48948 [==============================] - 172s 4ms/step - loss: 5.8034 - mean_absolute_error: 1.9743 - val_loss: 5.8107 - val_mean_absolute_error: 1.9736\n",
      "Epoch 66/100\n",
      "48948/48948 [==============================] - 162s 3ms/step - loss: 5.8030 - mean_absolute_error: 1.9745 - val_loss: 5.7999 - val_mean_absolute_error: 1.9737\n",
      "Epoch 67/100\n",
      "48948/48948 [==============================] - 142s 3ms/step - loss: 5.8024 - mean_absolute_error: 1.9741 - val_loss: 5.8184 - val_mean_absolute_error: 1.9764\n",
      "Epoch 68/100\n",
      "48948/48948 [==============================] - 136s 3ms/step - loss: 5.8011 - mean_absolute_error: 1.9738 - val_loss: 5.7857 - val_mean_absolute_error: 1.9709\n",
      "Epoch 69/100\n",
      "48948/48948 [==============================] - 135s 3ms/step - loss: 5.8005 - mean_absolute_error: 1.9737 - val_loss: 5.8006 - val_mean_absolute_error: 1.9810\n",
      "Epoch 70/100\n",
      "48948/48948 [==============================] - 143s 3ms/step - loss: 5.7989 - mean_absolute_error: 1.9735 - val_loss: 5.8244 - val_mean_absolute_error: 1.9713\n",
      "Epoch 71/100\n",
      "48948/48948 [==============================] - 136s 3ms/step - loss: 5.7962 - mean_absolute_error: 1.9728 - val_loss: 5.8117 - val_mean_absolute_error: 1.9764\n",
      "Epoch 72/100\n",
      "48948/48948 [==============================] - 145s 3ms/step - loss: 5.7952 - mean_absolute_error: 1.9725 - val_loss: 5.7901 - val_mean_absolute_error: 1.9686\n",
      "Epoch 73/100\n",
      "48948/48948 [==============================] - 136s 3ms/step - loss: 5.7951 - mean_absolute_error: 1.9728 - val_loss: 5.7849 - val_mean_absolute_error: 1.9785\n",
      "Epoch 74/100\n",
      "48948/48948 [==============================] - 144s 3ms/step - loss: 5.7962 - mean_absolute_error: 1.9730 - val_loss: 5.8041 - val_mean_absolute_error: 1.9777\n",
      "Epoch 75/100\n",
      "48948/48948 [==============================] - 132s 3ms/step - loss: 5.7947 - mean_absolute_error: 1.9724 - val_loss: 5.7946 - val_mean_absolute_error: 1.9731\n",
      "Epoch 76/100\n",
      "48948/48948 [==============================] - 134s 3ms/step - loss: 5.7942 - mean_absolute_error: 1.9725 - val_loss: 5.7816 - val_mean_absolute_error: 1.9745\n",
      "Epoch 77/100\n",
      "48948/48948 [==============================] - 144s 3ms/step - loss: 5.7939 - mean_absolute_error: 1.9724 - val_loss: 5.7945 - val_mean_absolute_error: 1.9715\n",
      "Epoch 78/100\n",
      "48948/48948 [==============================] - 136s 3ms/step - loss: 5.7929 - mean_absolute_error: 1.9722 - val_loss: 5.7931 - val_mean_absolute_error: 1.9774\n",
      "Epoch 79/100\n",
      "48948/48948 [==============================] - 144s 3ms/step - loss: 5.7927 - mean_absolute_error: 1.9721 - val_loss: 5.7866 - val_mean_absolute_error: 1.9714\n",
      "Epoch 80/100\n",
      "48948/48948 [==============================] - 135s 3ms/step - loss: 5.7921 - mean_absolute_error: 1.9722 - val_loss: 5.8103 - val_mean_absolute_error: 1.9773\n",
      "Epoch 81/100\n",
      "48948/48948 [==============================] - 144s 3ms/step - loss: 5.7921 - mean_absolute_error: 1.9721 - val_loss: 5.8018 - val_mean_absolute_error: 1.9774\n",
      "Epoch 82/100\n",
      "48948/48948 [==============================] - 134s 3ms/step - loss: 5.7895 - mean_absolute_error: 1.9717 - val_loss: 5.8122 - val_mean_absolute_error: 1.9697\n",
      "Epoch 83/100\n",
      "48948/48948 [==============================] - 139s 3ms/step - loss: 5.7902 - mean_absolute_error: 1.9716 - val_loss: 5.8217 - val_mean_absolute_error: 1.9691\n",
      "Epoch 84/100\n",
      "48948/48948 [==============================] - 144s 3ms/step - loss: 5.7891 - mean_absolute_error: 1.9715 - val_loss: 5.8029 - val_mean_absolute_error: 1.9777\n",
      "Epoch 85/100\n",
      "48948/48948 [==============================] - 137s 3ms/step - loss: 5.7870 - mean_absolute_error: 1.9708 - val_loss: 5.8090 - val_mean_absolute_error: 1.9773\n",
      "Epoch 86/100\n",
      "48948/48948 [==============================] - 146s 3ms/step - loss: 5.7886 - mean_absolute_error: 1.9714 - val_loss: 5.7974 - val_mean_absolute_error: 1.9749\n",
      "Epoch 86: early stopping\n",
      "12237/12237 [==============================] - 17s 1ms/step - loss: 5.7974 - mean_absolute_error: 1.9749\n",
      "Optimizer: Adam\n",
      "Mean Squared Error on Test Data: 5.80\n",
      "Mean Absolute Error on Test Data: 1.97\n",
      "Training stopped early at epoch 85 to prevent overfitting.\n",
      "Epoch 1/100\n",
      "48948/48948 [==============================] - 128s 3ms/step - loss: 6.3193 - mean_absolute_error: 2.0616 - val_loss: 6.2509 - val_mean_absolute_error: 2.0817\n",
      "Epoch 2/100\n",
      "48948/48948 [==============================] - 134s 3ms/step - loss: 6.1094 - mean_absolute_error: 2.0319 - val_loss: 6.0451 - val_mean_absolute_error: 2.0243\n",
      "Epoch 3/100\n",
      "48948/48948 [==============================] - 128s 3ms/step - loss: 6.0777 - mean_absolute_error: 2.0281 - val_loss: 6.1051 - val_mean_absolute_error: 2.0126\n",
      "Epoch 4/100\n",
      "48948/48948 [==============================] - 130s 3ms/step - loss: 6.0748 - mean_absolute_error: 2.0276 - val_loss: 6.1292 - val_mean_absolute_error: 2.0271\n",
      "Epoch 5/100\n",
      "48948/48948 [==============================] - 138s 3ms/step - loss: 6.0668 - mean_absolute_error: 2.0257 - val_loss: 6.0716 - val_mean_absolute_error: 2.0388\n",
      "Epoch 6/100\n",
      "48948/48948 [==============================] - 127s 3ms/step - loss: 6.0487 - mean_absolute_error: 2.0222 - val_loss: 6.0431 - val_mean_absolute_error: 2.0107\n",
      "Epoch 7/100\n",
      "48948/48948 [==============================] - 137s 3ms/step - loss: 6.0351 - mean_absolute_error: 2.0199 - val_loss: 6.0222 - val_mean_absolute_error: 2.0303\n",
      "Epoch 8/100\n",
      "48948/48948 [==============================] - 129s 3ms/step - loss: 6.0155 - mean_absolute_error: 2.0163 - val_loss: 6.0134 - val_mean_absolute_error: 2.0109\n",
      "Epoch 9/100\n",
      "48948/48948 [==============================] - 140s 3ms/step - loss: 6.0080 - mean_absolute_error: 2.0144 - val_loss: 5.9997 - val_mean_absolute_error: 2.0041\n",
      "Epoch 10/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48948/48948 [==============================] - 128s 3ms/step - loss: 5.9992 - mean_absolute_error: 2.0126 - val_loss: 5.9979 - val_mean_absolute_error: 2.0246\n",
      "Epoch 11/100\n",
      "48948/48948 [==============================] - 135s 3ms/step - loss: 5.9954 - mean_absolute_error: 2.0121 - val_loss: 5.9879 - val_mean_absolute_error: 2.0026\n",
      "Epoch 12/100\n",
      "48948/48948 [==============================] - 131s 3ms/step - loss: 5.9882 - mean_absolute_error: 2.0106 - val_loss: 5.9753 - val_mean_absolute_error: 2.0126\n",
      "Epoch 13/100\n",
      "48948/48948 [==============================] - 128s 3ms/step - loss: 5.9833 - mean_absolute_error: 2.0097 - val_loss: 5.9775 - val_mean_absolute_error: 2.0039\n",
      "Epoch 14/100\n",
      "48948/48948 [==============================] - 137s 3ms/step - loss: 5.9837 - mean_absolute_error: 2.0094 - val_loss: 5.9948 - val_mean_absolute_error: 2.0083\n",
      "Epoch 15/100\n",
      "48948/48948 [==============================] - 131s 3ms/step - loss: 5.9807 - mean_absolute_error: 2.0086 - val_loss: 5.9751 - val_mean_absolute_error: 2.0085\n",
      "Epoch 16/100\n",
      "48948/48948 [==============================] - 137s 3ms/step - loss: 5.9765 - mean_absolute_error: 2.0078 - val_loss: 5.9819 - val_mean_absolute_error: 2.0126\n",
      "Epoch 17/100\n",
      "48948/48948 [==============================] - 129s 3ms/step - loss: 5.9741 - mean_absolute_error: 2.0079 - val_loss: 5.9746 - val_mean_absolute_error: 2.0138\n",
      "Epoch 18/100\n",
      "48948/48948 [==============================] - 139s 3ms/step - loss: 5.9731 - mean_absolute_error: 2.0076 - val_loss: 5.9710 - val_mean_absolute_error: 2.0115\n",
      "Epoch 19/100\n",
      "48948/48948 [==============================] - 128s 3ms/step - loss: 5.9730 - mean_absolute_error: 2.0077 - val_loss: 5.9724 - val_mean_absolute_error: 2.0029\n",
      "Epoch 20/100\n",
      "48948/48948 [==============================] - 130s 3ms/step - loss: 5.9724 - mean_absolute_error: 2.0074 - val_loss: 5.9610 - val_mean_absolute_error: 2.0137\n",
      "Epoch 21/100\n",
      "48948/48948 [==============================] - 139s 3ms/step - loss: 5.9691 - mean_absolute_error: 2.0070 - val_loss: 5.9667 - val_mean_absolute_error: 2.0096\n",
      "Epoch 22/100\n",
      "48948/48948 [==============================] - 134s 3ms/step - loss: 5.9699 - mean_absolute_error: 2.0069 - val_loss: 6.0223 - val_mean_absolute_error: 1.9921\n",
      "Epoch 23/100\n",
      "48948/48948 [==============================] - 138s 3ms/step - loss: 5.9695 - mean_absolute_error: 2.0070 - val_loss: 5.9755 - val_mean_absolute_error: 2.0193\n",
      "Epoch 24/100\n",
      "48948/48948 [==============================] - 128s 3ms/step - loss: 5.9693 - mean_absolute_error: 2.0069 - val_loss: 5.9833 - val_mean_absolute_error: 2.0274\n",
      "Epoch 25/100\n",
      "48948/48948 [==============================] - 134s 3ms/step - loss: 5.9728 - mean_absolute_error: 2.0077 - val_loss: 6.0117 - val_mean_absolute_error: 2.0141\n",
      "Epoch 26/100\n",
      "48948/48948 [==============================] - 128s 3ms/step - loss: 5.9732 - mean_absolute_error: 2.0077 - val_loss: 5.9968 - val_mean_absolute_error: 2.0074\n",
      "Epoch 27/100\n",
      "48948/48948 [==============================] - 137s 3ms/step - loss: 5.9761 - mean_absolute_error: 2.0082 - val_loss: 5.9976 - val_mean_absolute_error: 2.0117\n",
      "Epoch 28/100\n",
      "48948/48948 [==============================] - 128s 3ms/step - loss: 5.9745 - mean_absolute_error: 2.0076 - val_loss: 5.9594 - val_mean_absolute_error: 2.0037\n",
      "Epoch 29/100\n",
      "48948/48948 [==============================] - 129s 3ms/step - loss: 5.9782 - mean_absolute_error: 2.0086 - val_loss: 5.9481 - val_mean_absolute_error: 2.0051\n",
      "Epoch 30/100\n",
      "48948/48948 [==============================] - 136s 3ms/step - loss: 5.9780 - mean_absolute_error: 2.0083 - val_loss: 6.0010 - val_mean_absolute_error: 2.0189\n",
      "Epoch 31/100\n",
      "48948/48948 [==============================] - 120s 2ms/step - loss: 5.9810 - mean_absolute_error: 2.0089 - val_loss: 5.9788 - val_mean_absolute_error: 2.0021\n",
      "Epoch 32/100\n",
      "48948/48948 [==============================] - 207s 4ms/step - loss: 5.9797 - mean_absolute_error: 2.0087 - val_loss: 6.0127 - val_mean_absolute_error: 2.0024\n",
      "Epoch 33/100\n",
      "48948/48948 [==============================] - 184s 4ms/step - loss: 5.9815 - mean_absolute_error: 2.0087 - val_loss: 5.9740 - val_mean_absolute_error: 2.0155\n",
      "Epoch 34/100\n",
      "48948/48948 [==============================] - 205s 4ms/step - loss: 5.9820 - mean_absolute_error: 2.0089 - val_loss: 5.9591 - val_mean_absolute_error: 2.0022\n",
      "Epoch 35/100\n",
      "48948/48948 [==============================] - 183s 4ms/step - loss: 5.9820 - mean_absolute_error: 2.0090 - val_loss: 5.9861 - val_mean_absolute_error: 2.0158\n",
      "Epoch 36/100\n",
      "48948/48948 [==============================] - 202s 4ms/step - loss: 5.9835 - mean_absolute_error: 2.0094 - val_loss: 5.9930 - val_mean_absolute_error: 2.0005\n",
      "Epoch 37/100\n",
      "48948/48948 [==============================] - 186s 4ms/step - loss: 5.9870 - mean_absolute_error: 2.0101 - val_loss: 5.9863 - val_mean_absolute_error: 2.0057\n",
      "Epoch 38/100\n",
      "48948/48948 [==============================] - 205s 4ms/step - loss: 5.9897 - mean_absolute_error: 2.0104 - val_loss: 5.9880 - val_mean_absolute_error: 2.0101\n",
      "Epoch 39/100\n",
      "48948/48948 [==============================] - 186s 4ms/step - loss: 5.9900 - mean_absolute_error: 2.0107 - val_loss: 5.9627 - val_mean_absolute_error: 2.0099\n",
      "Epoch 39: early stopping\n",
      "12237/12237 [==============================] - 25s 2ms/step - loss: 5.9627 - mean_absolute_error: 2.0099\n",
      "Optimizer: RMSprop\n",
      "Mean Squared Error on Test Data: 5.96\n",
      "Mean Absolute Error on Test Data: 2.01\n",
      "Training stopped early at epoch 38 to prevent overfitting.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "optimizers = [SGD(learning_rate=0.001), Adam(learning_rate=0.001), RMSprop(learning_rate=0.001)]\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "\n",
    "for optimizer in optimizers:\n",
    "    model = Sequential([\n",
    "                Dense(512, activation='relu', input_dim=X_train.shape[1]),\n",
    "                Dense(256, activation='relu'),\n",
    "                Dense(128, activation='relu'),\n",
    "                Dense(1)\n",
    "            ])\n",
    "\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
    "\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=32, callbacks=[early_stopping])\n",
    "\n",
    "    loss, mae = model.evaluate(X_test, y_test)\n",
    "    print(f\"Optimizer: {optimizer.get_config()['name']}\")\n",
    "    print(f\"Mean Squared Error on Test Data: {loss:.2f}\")\n",
    "    print(f\"Mean Absolute Error on Test Data: {mae:.2f}\")\n",
    "\n",
    "    if early_stopping.stopped_epoch > 0:\n",
    "        print(f\"Training stopped early at epoch {early_stopping.stopped_epoch} to prevent overfitting.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c821ecc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
