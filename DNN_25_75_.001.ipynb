{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b14ab4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "parquet_file_path = 'yellow_tripdata_2020-01.parquet'\n",
    "df = pd.read_parquet(parquet_file_path, engine='pyarrow')\n",
    "\n",
    "df['tpep_pickup_datetime'] = pd.to_datetime(df['tpep_pickup_datetime'])\n",
    "df['tpep_dropoff_datetime'] = pd.to_datetime(df['tpep_dropoff_datetime'])\n",
    "\n",
    "df['pickup_date'] = df['tpep_pickup_datetime'].dt.date\n",
    "df=df[df['tpep_pickup_datetime'].dt.month==1]\n",
    "df['time_taken'] = (df['tpep_dropoff_datetime'] - df['tpep_pickup_datetime']).dt.total_seconds() / 60\n",
    "\n",
    "df.to_csv('updated_dataset1.csv', index=False)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec634a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>pickup_date</th>\n",
       "      <th>time_taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>238</td>\n",
       "      <td>239</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.47</td>\n",
       "      <td>0.3</td>\n",
       "      <td>11.27</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>4.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>239</td>\n",
       "      <td>238</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.3</td>\n",
       "      <td>12.30</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>7.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>246</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.3</td>\n",
       "      <td>17.55</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>16.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>161</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.15</td>\n",
       "      <td>0.3</td>\n",
       "      <td>24.95</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>25.283333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43</td>\n",
       "      <td>239</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.96</td>\n",
       "      <td>0.3</td>\n",
       "      <td>11.76</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>5.616667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6339372</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>48</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>17.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.26</td>\n",
       "      <td>0.3</td>\n",
       "      <td>25.56</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>21.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6339373</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>163</td>\n",
       "      <td>246</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.96</td>\n",
       "      <td>0.3</td>\n",
       "      <td>17.76</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>14.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6339374</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>164</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20.16</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6339375</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>12.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.3</td>\n",
       "      <td>19.56</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>16.283333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6339376</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.61</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>142</td>\n",
       "      <td>2</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>12.30</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>9.633333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4485618 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         passenger_count  trip_distance  RatecodeID  PULocationID  \\\n",
       "0                    1.0           1.20         1.0           238   \n",
       "1                    1.0           1.20         1.0           239   \n",
       "8                    2.0           2.40         1.0           246   \n",
       "10                   1.0           3.30         1.0           161   \n",
       "11                   1.0           1.07         1.0            43   \n",
       "...                  ...            ...         ...           ...   \n",
       "6339372              1.0           4.11         1.0            48   \n",
       "6339373              1.0           2.10         1.0           163   \n",
       "6339374              1.0           2.13         1.0           164   \n",
       "6339375              1.0           2.55         1.0            79   \n",
       "6339376              1.0           1.61         1.0           100   \n",
       "\n",
       "         DOLocationID  payment_type  fare_amount  extra  mta_tax  tip_amount  \\\n",
       "0                 239             1          6.0    3.0      0.5        1.47   \n",
       "1                 238             1          7.0    3.0      0.5        1.50   \n",
       "8                  79             1         12.0    3.0      0.5        1.75   \n",
       "10                144             1         17.0    3.0      0.5        4.15   \n",
       "11                239             1          6.0    0.5      0.5        1.96   \n",
       "...               ...           ...          ...    ...      ...         ...   \n",
       "6339372            75             1         17.5    0.5      0.5        4.26   \n",
       "6339373           246             1         11.0    0.5      0.5        2.96   \n",
       "6339374            79             1         13.0    0.5      0.5        3.36   \n",
       "6339375            68             1         12.5    0.5      0.5        3.26   \n",
       "6339376           142             2          8.5    0.5      0.5        0.00   \n",
       "\n",
       "         improvement_surcharge  total_amount  congestion_surcharge  \\\n",
       "0                          0.3         11.27                   2.5   \n",
       "1                          0.3         12.30                   2.5   \n",
       "8                          0.3         17.55                   2.5   \n",
       "10                         0.3         24.95                   2.5   \n",
       "11                         0.3         11.76                   2.5   \n",
       "...                        ...           ...                   ...   \n",
       "6339372                    0.3         25.56                   2.5   \n",
       "6339373                    0.3         17.76                   2.5   \n",
       "6339374                    0.3         20.16                   2.5   \n",
       "6339375                    0.3         19.56                   2.5   \n",
       "6339376                    0.3         12.30                   2.5   \n",
       "\n",
       "        pickup_date  time_taken  \n",
       "0        2020-01-01    4.800000  \n",
       "1        2020-01-01    7.416667  \n",
       "8        2020-01-01   16.866667  \n",
       "10       2020-01-01   25.283333  \n",
       "11       2020-01-01    5.616667  \n",
       "...             ...         ...  \n",
       "6339372  2020-01-31   21.500000  \n",
       "6339373  2020-01-31   14.233333  \n",
       "6339374  2020-01-31   19.000000  \n",
       "6339375  2020-01-31   16.283333  \n",
       "6339376  2020-01-31    9.633333  \n",
       "\n",
       "[4485618 rows x 15 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_csv('updated_dataset1.csv', low_memory=False)\n",
    "df2['pickup_date'] = pd.to_datetime(df2['pickup_date'], format='%Y-%m-%d')\n",
    "columns_to_remove = ['VendorID', 'store_and_fwd_flag', 'airport_fee','tpep_pickup_datetime','tpep_dropoff_datetime', 'tolls_amount']\n",
    "df2.drop(columns=columns_to_remove, inplace=True)\n",
    "df2.dropna(how='any', inplace=True)\n",
    "df2 = df2[df2['passenger_count'] != 0]\n",
    "\n",
    "df2 = df2[df2['trip_distance'] > 1]\n",
    "df2 = df2[df2['time_taken'] > 1]\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c22bf904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_date</th>\n",
       "      <th>tavg</th>\n",
       "      <th>tmin</th>\n",
       "      <th>tmax</th>\n",
       "      <th>wspd</th>\n",
       "      <th>pres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.3</td>\n",
       "      <td>1008.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>8.9</td>\n",
       "      <td>12.4</td>\n",
       "      <td>1013.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>7.6</td>\n",
       "      <td>6.7</td>\n",
       "      <td>8.3</td>\n",
       "      <td>8.4</td>\n",
       "      <td>1010.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>8.2</td>\n",
       "      <td>6.7</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5.7</td>\n",
       "      <td>1003.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>4.6</td>\n",
       "      <td>2.8</td>\n",
       "      <td>7.2</td>\n",
       "      <td>8.2</td>\n",
       "      <td>1010.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-01-07</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>6.7</td>\n",
       "      <td>10.4</td>\n",
       "      <td>1016.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-01-08</td>\n",
       "      <td>2.6</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>6.7</td>\n",
       "      <td>13.4</td>\n",
       "      <td>1016.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-01-09</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>-3.3</td>\n",
       "      <td>2.2</td>\n",
       "      <td>9.1</td>\n",
       "      <td>1038.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-01-10</td>\n",
       "      <td>6.4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>11.7</td>\n",
       "      <td>14.5</td>\n",
       "      <td>1034.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2020-01-12</td>\n",
       "      <td>15.7</td>\n",
       "      <td>9.4</td>\n",
       "      <td>19.4</td>\n",
       "      <td>15.5</td>\n",
       "      <td>1018.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2020-01-14</td>\n",
       "      <td>6.3</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>9.9</td>\n",
       "      <td>1025.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2020-01-15</td>\n",
       "      <td>8.2</td>\n",
       "      <td>6.1</td>\n",
       "      <td>11.7</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1020.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2020-01-16</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.6</td>\n",
       "      <td>1015.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2020-01-17</td>\n",
       "      <td>-1.2</td>\n",
       "      <td>-3.9</td>\n",
       "      <td>2.2</td>\n",
       "      <td>8.8</td>\n",
       "      <td>1034.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2020-01-18</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>10.2</td>\n",
       "      <td>1028.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2020-01-19</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>7.2</td>\n",
       "      <td>10.2</td>\n",
       "      <td>1008.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2020-01-20</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>9.1</td>\n",
       "      <td>1024.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2020-01-21</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>-4.4</td>\n",
       "      <td>3.3</td>\n",
       "      <td>8.9</td>\n",
       "      <td>1030.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>5.6</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1031.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1029.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>6.5</td>\n",
       "      <td>3.3</td>\n",
       "      <td>11.7</td>\n",
       "      <td>10.6</td>\n",
       "      <td>1027.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2020-01-25</td>\n",
       "      <td>6.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>10.0</td>\n",
       "      <td>22.9</td>\n",
       "      <td>1014.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2020-01-26</td>\n",
       "      <td>5.5</td>\n",
       "      <td>3.3</td>\n",
       "      <td>8.9</td>\n",
       "      <td>14.9</td>\n",
       "      <td>1009.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2020-01-28</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.9</td>\n",
       "      <td>7.2</td>\n",
       "      <td>6.3</td>\n",
       "      <td>1010.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2020-01-29</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.1</td>\n",
       "      <td>7.2</td>\n",
       "      <td>7.8</td>\n",
       "      <td>1018.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2020-01-30</td>\n",
       "      <td>1.3</td>\n",
       "      <td>-1.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>10.7</td>\n",
       "      <td>1026.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.1</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1026.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pickup_date  tavg  tmin  tmax  wspd    pres\n",
       "0   2020-01-01   3.6   1.7   5.0  17.3  1008.2\n",
       "1   2020-01-02   4.7   0.6   8.9  12.4  1013.9\n",
       "2   2020-01-03   7.6   6.7   8.3   8.4  1010.2\n",
       "3   2020-01-04   8.2   6.7   9.4   5.7  1003.7\n",
       "4   2020-01-05   4.6   2.8   7.2   8.2  1010.1\n",
       "6   2020-01-07   4.7   3.3   6.7  10.4  1016.2\n",
       "7   2020-01-08   2.6  -0.6   6.7  13.4  1016.6\n",
       "8   2020-01-09  -0.6  -3.3   2.2   9.1  1038.8\n",
       "9   2020-01-10   6.4   1.1  11.7  14.5  1034.5\n",
       "11  2020-01-12  15.7   9.4  19.4  15.5  1018.1\n",
       "13  2020-01-14   6.3   5.0   7.8   9.9  1025.3\n",
       "14  2020-01-15   8.2   6.1  11.7   9.0  1020.9\n",
       "15  2020-01-16   6.7   2.2  10.0  10.6  1015.1\n",
       "16  2020-01-17  -1.2  -3.9   2.2   8.8  1034.7\n",
       "17  2020-01-18  -2.2  -5.0   2.8  10.2  1028.5\n",
       "18  2020-01-19   4.0   0.6   7.2  10.2  1008.9\n",
       "19  2020-01-20  -1.7  -5.0   2.8   9.1  1024.2\n",
       "20  2020-01-21  -1.5  -4.4   3.3   8.9  1030.8\n",
       "21  2020-01-22   1.0  -2.2   5.6   8.1  1031.3\n",
       "22  2020-01-23   3.5   0.0   7.2   7.5  1029.4\n",
       "23  2020-01-24   6.5   3.3  11.7  10.6  1027.4\n",
       "24  2020-01-25   6.6   4.4  10.0  22.9  1014.5\n",
       "25  2020-01-26   5.5   3.3   8.9  14.9  1009.3\n",
       "27  2020-01-28   4.9   3.9   7.2   6.3  1010.2\n",
       "28  2020-01-29   3.5   1.1   7.2   7.8  1018.2\n",
       "29  2020-01-30   1.3  -1.7   4.4  10.7  1026.3\n",
       "30  2020-01-31   4.3   2.2   6.1   7.5  1026.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_excel('weather.xlsx')\n",
    "df1['pickup_date'] = pd.to_datetime(df1['pickup_date'], format='%Y-%m-%d')\n",
    "\n",
    "columns_to_remove = ['prcp', 'snow', 'wdir','wpgt', 'tsun']\n",
    "df1.drop(columns=columns_to_remove, inplace=True)\n",
    "df1.dropna(how='any', inplace=True)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92f1a9d4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>RatecodeID</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>payment_type</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>extra</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>congestion_surcharge</th>\n",
       "      <th>pickup_date</th>\n",
       "      <th>time_taken</th>\n",
       "      <th>tavg</th>\n",
       "      <th>tmin</th>\n",
       "      <th>tmax</th>\n",
       "      <th>wspd</th>\n",
       "      <th>pres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>238</td>\n",
       "      <td>239</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.47</td>\n",
       "      <td>0.3</td>\n",
       "      <td>11.27</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>4.800000</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.3</td>\n",
       "      <td>1008.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>239</td>\n",
       "      <td>238</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.3</td>\n",
       "      <td>12.30</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>7.416667</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.3</td>\n",
       "      <td>1008.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>246</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0.3</td>\n",
       "      <td>17.55</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>16.866667</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.3</td>\n",
       "      <td>1008.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>161</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.15</td>\n",
       "      <td>0.3</td>\n",
       "      <td>24.95</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>25.283333</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.3</td>\n",
       "      <td>1008.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43</td>\n",
       "      <td>239</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.96</td>\n",
       "      <td>0.3</td>\n",
       "      <td>11.76</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>5.616667</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.3</td>\n",
       "      <td>1008.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4485613</th>\n",
       "      <td>1.0</td>\n",
       "      <td>4.11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>48</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>17.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.26</td>\n",
       "      <td>0.3</td>\n",
       "      <td>25.56</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.1</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1026.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4485614</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>163</td>\n",
       "      <td>246</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.96</td>\n",
       "      <td>0.3</td>\n",
       "      <td>17.76</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>14.233333</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.1</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1026.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4485615</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>164</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.36</td>\n",
       "      <td>0.3</td>\n",
       "      <td>20.16</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.1</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1026.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4485616</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>79</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>12.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.3</td>\n",
       "      <td>19.56</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>16.283333</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.1</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1026.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4485617</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.61</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100</td>\n",
       "      <td>142</td>\n",
       "      <td>2</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>12.30</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>9.633333</td>\n",
       "      <td>4.3</td>\n",
       "      <td>2.2</td>\n",
       "      <td>6.1</td>\n",
       "      <td>7.5</td>\n",
       "      <td>1026.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4485618 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         passenger_count  trip_distance  RatecodeID  PULocationID  \\\n",
       "0                    1.0           1.20         1.0           238   \n",
       "1                    1.0           1.20         1.0           239   \n",
       "2                    2.0           2.40         1.0           246   \n",
       "3                    1.0           3.30         1.0           161   \n",
       "4                    1.0           1.07         1.0            43   \n",
       "...                  ...            ...         ...           ...   \n",
       "4485613              1.0           4.11         1.0            48   \n",
       "4485614              1.0           2.10         1.0           163   \n",
       "4485615              1.0           2.13         1.0           164   \n",
       "4485616              1.0           2.55         1.0            79   \n",
       "4485617              1.0           1.61         1.0           100   \n",
       "\n",
       "         DOLocationID  payment_type  fare_amount  extra  mta_tax  tip_amount  \\\n",
       "0                 239             1          6.0    3.0      0.5        1.47   \n",
       "1                 238             1          7.0    3.0      0.5        1.50   \n",
       "2                  79             1         12.0    3.0      0.5        1.75   \n",
       "3                 144             1         17.0    3.0      0.5        4.15   \n",
       "4                 239             1          6.0    0.5      0.5        1.96   \n",
       "...               ...           ...          ...    ...      ...         ...   \n",
       "4485613            75             1         17.5    0.5      0.5        4.26   \n",
       "4485614           246             1         11.0    0.5      0.5        2.96   \n",
       "4485615            79             1         13.0    0.5      0.5        3.36   \n",
       "4485616            68             1         12.5    0.5      0.5        3.26   \n",
       "4485617           142             2          8.5    0.5      0.5        0.00   \n",
       "\n",
       "         improvement_surcharge  total_amount  congestion_surcharge  \\\n",
       "0                          0.3         11.27                   2.5   \n",
       "1                          0.3         12.30                   2.5   \n",
       "2                          0.3         17.55                   2.5   \n",
       "3                          0.3         24.95                   2.5   \n",
       "4                          0.3         11.76                   2.5   \n",
       "...                        ...           ...                   ...   \n",
       "4485613                    0.3         25.56                   2.5   \n",
       "4485614                    0.3         17.76                   2.5   \n",
       "4485615                    0.3         20.16                   2.5   \n",
       "4485616                    0.3         19.56                   2.5   \n",
       "4485617                    0.3         12.30                   2.5   \n",
       "\n",
       "        pickup_date  time_taken  tavg  tmin  tmax  wspd    pres  \n",
       "0        2020-01-01    4.800000   3.6   1.7   5.0  17.3  1008.2  \n",
       "1        2020-01-01    7.416667   3.6   1.7   5.0  17.3  1008.2  \n",
       "2        2020-01-01   16.866667   3.6   1.7   5.0  17.3  1008.2  \n",
       "3        2020-01-01   25.283333   3.6   1.7   5.0  17.3  1008.2  \n",
       "4        2020-01-01    5.616667   3.6   1.7   5.0  17.3  1008.2  \n",
       "...             ...         ...   ...   ...   ...   ...     ...  \n",
       "4485613  2020-01-31   21.500000   4.3   2.2   6.1   7.5  1026.0  \n",
       "4485614  2020-01-31   14.233333   4.3   2.2   6.1   7.5  1026.0  \n",
       "4485615  2020-01-31   19.000000   4.3   2.2   6.1   7.5  1026.0  \n",
       "4485616  2020-01-31   16.283333   4.3   2.2   6.1   7.5  1026.0  \n",
       "4485617  2020-01-31    9.633333   4.3   2.2   6.1   7.5  1026.0  \n",
       "\n",
       "[4485618 rows x 20 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = df2.merge(df1, left_on='pickup_date', right_on='pickup_date', how='left')\n",
    "\n",
    "columns_to_populate = ['tavg', 'tmin', 'tmax', 'wspd']\n",
    "for col in columns_to_populate:\n",
    "    merged_df[col].fillna(merged_df[f'{col}'], inplace=True)\n",
    "#merged_df=merged_df[merged_df['pickup_date'].dt.day<=10]\n",
    "#merged_df = merged_df[merged_df['tavg'] > 0]\n",
    "#merged_df = merged_df[merged_df['wspd'] > 0]\n",
    "merged_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4afdfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_columns = ['trip_distance','PULocationID', 'DOLocationID', 'time_taken', 'tavg', 'pres']\n",
    "\n",
    "new_df = merged_df[selected_columns]\n",
    "#new_df=new_df[new_df['PULocationID'].isin([132, 161, 237, 236, 186, 162, 230, 142, 48])]\n",
    "#new_df=new_df[new_df['DOLocationID'].isin([236,237,161,239,142, 238, 162])]\n",
    "new_df = new_df.dropna(subset=['tavg', 'pres'])\n",
    "new_df = new_df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c3310bd",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data - X_train shape: (1566329, 5) y_train shape: (1566329,)\n",
      "Testing data - X_test shape: (391583, 5) y_test shape: (391583,)\n",
      "         trip_distance  PULocationID  DOLocationID  time_taken  tavg    pres\n",
      "0                 3.00           107            48   18.016667   6.4  1034.5\n",
      "6                 2.61           151            42   15.016667  -1.7  1024.2\n",
      "8                 4.60            68           255   18.450000   3.5  1018.2\n",
      "10                1.41           140           236   10.683333   6.7  1015.1\n",
      "14                3.36           140           137   14.666667  -1.2  1034.7\n",
      "...                ...           ...           ...         ...   ...     ...\n",
      "3923021           3.20           163            79   10.250000   5.5  1009.3\n",
      "3923025           2.92           142           166   17.533333   1.0  1031.3\n",
      "3923026           3.50           249           237   15.550000   5.5  1009.3\n",
      "3923028           1.77           161           236    9.916667   4.7  1013.9\n",
      "3923029           1.24            68           249   13.666667  -2.2  1028.5\n",
      "\n",
      "[1957912 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "p_25 = new_df['time_taken'].quantile(0.25)\n",
    "p_75 = new_df['time_taken'].quantile(0.75)\n",
    "new_df = new_df[(new_df['time_taken'] > p_27) & (new_df['time_taken'] < p_72)]\n",
    "#new_df.sort_values('DOLocationID', ascending=False, inplace=True)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = new_df.drop(columns=['time_taken'])\n",
    "y = new_df['time_taken']  \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(\"Training data - X_train shape:\", X_train.shape, \"y_train shape:\", y_train.shape)\n",
    "print(\"Testing data - X_test shape:\", X_test.shape, \"y_test shape:\", y_test.shape)\n",
    "print(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "899ea7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "48948/48948 [==============================] - 192s 4ms/step - loss: 6.2146 - mean_absolute_error: 2.0439 - val_loss: 6.0582 - val_mean_absolute_error: 2.0207\n",
      "Epoch 2/100\n",
      "48948/48948 [==============================] - 186s 4ms/step - loss: 6.0393 - mean_absolute_error: 2.0209 - val_loss: 6.0068 - val_mean_absolute_error: 2.0093\n",
      "Epoch 3/100\n",
      "48948/48948 [==============================] - 191s 4ms/step - loss: 6.0062 - mean_absolute_error: 2.0149 - val_loss: 5.9831 - val_mean_absolute_error: 2.0007\n",
      "Epoch 4/100\n",
      "48948/48948 [==============================] - 190s 4ms/step - loss: 5.9789 - mean_absolute_error: 2.0099 - val_loss: 5.9482 - val_mean_absolute_error: 2.0022\n",
      "Epoch 5/100\n",
      "48948/48948 [==============================] - 196s 4ms/step - loss: 5.9521 - mean_absolute_error: 2.0046 - val_loss: 5.9187 - val_mean_absolute_error: 2.0012\n",
      "Epoch 6/100\n",
      "48948/48948 [==============================] - 219s 4ms/step - loss: 5.9306 - mean_absolute_error: 2.0004 - val_loss: 5.9069 - val_mean_absolute_error: 1.9892\n",
      "Epoch 7/100\n",
      "48948/48948 [==============================] - 242s 5ms/step - loss: 5.9127 - mean_absolute_error: 1.9967 - val_loss: 5.9020 - val_mean_absolute_error: 2.0040\n",
      "Epoch 8/100\n",
      "48948/48948 [==============================] - 232s 5ms/step - loss: 5.8966 - mean_absolute_error: 1.9933 - val_loss: 5.9114 - val_mean_absolute_error: 1.9868\n",
      "Epoch 9/100\n",
      "48948/48948 [==============================] - 225s 5ms/step - loss: 5.8816 - mean_absolute_error: 1.9906 - val_loss: 5.8512 - val_mean_absolute_error: 1.9827\n",
      "Epoch 10/100\n",
      "48948/48948 [==============================] - 233s 5ms/step - loss: 5.8665 - mean_absolute_error: 1.9875 - val_loss: 5.8509 - val_mean_absolute_error: 1.9850\n",
      "Epoch 11/100\n",
      "48948/48948 [==============================] - 233s 5ms/step - loss: 5.8512 - mean_absolute_error: 1.9843 - val_loss: 5.8292 - val_mean_absolute_error: 1.9815\n",
      "Epoch 12/100\n",
      "48948/48948 [==============================] - 229s 5ms/step - loss: 5.8359 - mean_absolute_error: 1.9812 - val_loss: 5.8318 - val_mean_absolute_error: 1.9919\n",
      "Epoch 13/100\n",
      "48948/48948 [==============================] - 254s 5ms/step - loss: 5.8214 - mean_absolute_error: 1.9783 - val_loss: 5.7925 - val_mean_absolute_error: 1.9763\n",
      "Epoch 14/100\n",
      "48948/48948 [==============================] - 262s 5ms/step - loss: 5.8066 - mean_absolute_error: 1.9753 - val_loss: 5.7914 - val_mean_absolute_error: 1.9685\n",
      "Epoch 15/100\n",
      "48948/48948 [==============================] - 274s 6ms/step - loss: 5.7942 - mean_absolute_error: 1.9728 - val_loss: 5.8065 - val_mean_absolute_error: 1.9674\n",
      "Epoch 16/100\n",
      "48948/48948 [==============================] - 255s 5ms/step - loss: 5.7819 - mean_absolute_error: 1.9701 - val_loss: 5.7932 - val_mean_absolute_error: 1.9672\n",
      "Epoch 17/100\n",
      "48948/48948 [==============================] - 227s 5ms/step - loss: 5.7719 - mean_absolute_error: 1.9682 - val_loss: 5.8399 - val_mean_absolute_error: 1.9956\n",
      "Epoch 18/100\n",
      "48948/48948 [==============================] - 230s 5ms/step - loss: 5.7614 - mean_absolute_error: 1.9658 - val_loss: 5.7581 - val_mean_absolute_error: 1.9580\n",
      "Epoch 19/100\n",
      "48948/48948 [==============================] - 231s 5ms/step - loss: 5.7526 - mean_absolute_error: 1.9641 - val_loss: 5.7394 - val_mean_absolute_error: 1.9614\n",
      "Epoch 20/100\n",
      "48948/48948 [==============================] - 226s 5ms/step - loss: 5.7430 - mean_absolute_error: 1.9620 - val_loss: 5.7467 - val_mean_absolute_error: 1.9668\n",
      "Epoch 21/100\n",
      "48948/48948 [==============================] - 226s 5ms/step - loss: 5.7363 - mean_absolute_error: 1.9607 - val_loss: 5.7391 - val_mean_absolute_error: 1.9703\n",
      "Epoch 22/100\n",
      "48948/48948 [==============================] - 228s 5ms/step - loss: 5.7270 - mean_absolute_error: 1.9588 - val_loss: 5.7098 - val_mean_absolute_error: 1.9550\n",
      "Epoch 23/100\n",
      "48948/48948 [==============================] - 226s 5ms/step - loss: 5.7200 - mean_absolute_error: 1.9573 - val_loss: 5.7347 - val_mean_absolute_error: 1.9700\n",
      "Epoch 24/100\n",
      "48948/48948 [==============================] - 229s 5ms/step - loss: 5.7124 - mean_absolute_error: 1.9559 - val_loss: 5.7539 - val_mean_absolute_error: 1.9557\n",
      "Epoch 25/100\n",
      "48948/48948 [==============================] - 230s 5ms/step - loss: 5.7053 - mean_absolute_error: 1.9546 - val_loss: 5.7300 - val_mean_absolute_error: 1.9548\n",
      "Epoch 26/100\n",
      "48948/48948 [==============================] - 236s 5ms/step - loss: 5.6994 - mean_absolute_error: 1.9529 - val_loss: 5.7075 - val_mean_absolute_error: 1.9596\n",
      "Epoch 27/100\n",
      "48948/48948 [==============================] - 230s 5ms/step - loss: 5.6912 - mean_absolute_error: 1.9514 - val_loss: 5.6897 - val_mean_absolute_error: 1.9486\n",
      "Epoch 28/100\n",
      "48948/48948 [==============================] - 232s 5ms/step - loss: 5.6846 - mean_absolute_error: 1.9499 - val_loss: 5.6842 - val_mean_absolute_error: 1.9535\n",
      "Epoch 29/100\n",
      "48948/48948 [==============================] - 230s 5ms/step - loss: 5.6791 - mean_absolute_error: 1.9489 - val_loss: 5.6880 - val_mean_absolute_error: 1.9501\n",
      "Epoch 30/100\n",
      "48948/48948 [==============================] - 226s 5ms/step - loss: 5.6732 - mean_absolute_error: 1.9477 - val_loss: 5.6842 - val_mean_absolute_error: 1.9451\n",
      "Epoch 31/100\n",
      "48948/48948 [==============================] - 229s 5ms/step - loss: 5.6664 - mean_absolute_error: 1.9462 - val_loss: 5.7037 - val_mean_absolute_error: 1.9549\n",
      "Epoch 32/100\n",
      "48948/48948 [==============================] - 230s 5ms/step - loss: 5.6613 - mean_absolute_error: 1.9449 - val_loss: 5.6835 - val_mean_absolute_error: 1.9598\n",
      "Epoch 33/100\n",
      "48948/48948 [==============================] - 227s 5ms/step - loss: 5.6562 - mean_absolute_error: 1.9441 - val_loss: 5.6651 - val_mean_absolute_error: 1.9507\n",
      "Epoch 34/100\n",
      "48948/48948 [==============================] - 244s 5ms/step - loss: 5.6505 - mean_absolute_error: 1.9427 - val_loss: 5.6724 - val_mean_absolute_error: 1.9578\n",
      "Epoch 35/100\n",
      "48948/48948 [==============================] - 247s 5ms/step - loss: 5.6455 - mean_absolute_error: 1.9417 - val_loss: 5.6602 - val_mean_absolute_error: 1.9505\n",
      "Epoch 36/100\n",
      "48948/48948 [==============================] - 243s 5ms/step - loss: 5.6394 - mean_absolute_error: 1.9406 - val_loss: 5.7162 - val_mean_absolute_error: 1.9566\n",
      "Epoch 37/100\n",
      "48948/48948 [==============================] - 244s 5ms/step - loss: 5.6353 - mean_absolute_error: 1.9397 - val_loss: 5.6463 - val_mean_absolute_error: 1.9440\n",
      "Epoch 38/100\n",
      "48948/48948 [==============================] - 246s 5ms/step - loss: 5.6308 - mean_absolute_error: 1.9386 - val_loss: 5.6512 - val_mean_absolute_error: 1.9350\n",
      "Epoch 39/100\n",
      "48948/48948 [==============================] - 248s 5ms/step - loss: 5.6260 - mean_absolute_error: 1.9376 - val_loss: 5.6597 - val_mean_absolute_error: 1.9586\n",
      "Epoch 40/100\n",
      "48948/48948 [==============================] - 247s 5ms/step - loss: 5.6213 - mean_absolute_error: 1.9365 - val_loss: 5.6469 - val_mean_absolute_error: 1.9403\n",
      "Epoch 41/100\n",
      "48948/48948 [==============================] - 248s 5ms/step - loss: 5.6170 - mean_absolute_error: 1.9357 - val_loss: 5.6297 - val_mean_absolute_error: 1.9322\n",
      "Epoch 42/100\n",
      "48948/48948 [==============================] - 248s 5ms/step - loss: 5.6126 - mean_absolute_error: 1.9351 - val_loss: 5.6547 - val_mean_absolute_error: 1.9453\n",
      "Epoch 43/100\n",
      "48948/48948 [==============================] - 249s 5ms/step - loss: 5.6087 - mean_absolute_error: 1.9340 - val_loss: 5.6560 - val_mean_absolute_error: 1.9290\n",
      "Epoch 44/100\n",
      "48948/48948 [==============================] - 243s 5ms/step - loss: 5.6041 - mean_absolute_error: 1.9331 - val_loss: 5.6395 - val_mean_absolute_error: 1.9412\n",
      "Epoch 45/100\n",
      "48948/48948 [==============================] - 243s 5ms/step - loss: 5.5995 - mean_absolute_error: 1.9323 - val_loss: 5.6246 - val_mean_absolute_error: 1.9409\n",
      "Epoch 46/100\n",
      "48948/48948 [==============================] - 250s 5ms/step - loss: 5.5968 - mean_absolute_error: 1.9313 - val_loss: 5.6249 - val_mean_absolute_error: 1.9338\n",
      "Epoch 47/100\n",
      "48948/48948 [==============================] - 248s 5ms/step - loss: 5.5918 - mean_absolute_error: 1.9306 - val_loss: 5.6530 - val_mean_absolute_error: 1.9322\n",
      "Epoch 48/100\n",
      "48948/48948 [==============================] - 250s 5ms/step - loss: 5.5873 - mean_absolute_error: 1.9295 - val_loss: 5.6074 - val_mean_absolute_error: 1.9260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/100\n",
      "48948/48948 [==============================] - 245s 5ms/step - loss: 5.5836 - mean_absolute_error: 1.9287 - val_loss: 5.6663 - val_mean_absolute_error: 1.9442\n",
      "Epoch 50/100\n",
      "48948/48948 [==============================] - 250s 5ms/step - loss: 5.5809 - mean_absolute_error: 1.9283 - val_loss: 5.6104 - val_mean_absolute_error: 1.9411\n",
      "Epoch 51/100\n",
      "48948/48948 [==============================] - 246s 5ms/step - loss: 5.5762 - mean_absolute_error: 1.9272 - val_loss: 5.5983 - val_mean_absolute_error: 1.9364\n",
      "Epoch 52/100\n",
      "48948/48948 [==============================] - 242s 5ms/step - loss: 5.5725 - mean_absolute_error: 1.9264 - val_loss: 5.6332 - val_mean_absolute_error: 1.9475\n",
      "Epoch 53/100\n",
      "48948/48948 [==============================] - 244s 5ms/step - loss: 5.5684 - mean_absolute_error: 1.9257 - val_loss: 5.6096 - val_mean_absolute_error: 1.9372\n",
      "Epoch 54/100\n",
      "48948/48948 [==============================] - 248s 5ms/step - loss: 5.5660 - mean_absolute_error: 1.9249 - val_loss: 5.6010 - val_mean_absolute_error: 1.9358\n",
      "Epoch 55/100\n",
      "48948/48948 [==============================] - 244s 5ms/step - loss: 5.5621 - mean_absolute_error: 1.9240 - val_loss: 5.5856 - val_mean_absolute_error: 1.9345\n",
      "Epoch 56/100\n",
      "48948/48948 [==============================] - 247s 5ms/step - loss: 5.5571 - mean_absolute_error: 1.9234 - val_loss: 5.5800 - val_mean_absolute_error: 1.9218\n",
      "Epoch 57/100\n",
      "48948/48948 [==============================] - 244s 5ms/step - loss: 5.5547 - mean_absolute_error: 1.9225 - val_loss: 5.5917 - val_mean_absolute_error: 1.9329\n",
      "Epoch 58/100\n",
      "48948/48948 [==============================] - 248s 5ms/step - loss: 5.5518 - mean_absolute_error: 1.9220 - val_loss: 5.6448 - val_mean_absolute_error: 1.9398\n",
      "Epoch 59/100\n",
      "48948/48948 [==============================] - 252s 5ms/step - loss: 5.5477 - mean_absolute_error: 1.9213 - val_loss: 5.5946 - val_mean_absolute_error: 1.9225\n",
      "Epoch 60/100\n",
      "48948/48948 [==============================] - 267s 5ms/step - loss: 5.5444 - mean_absolute_error: 1.9204 - val_loss: 5.5791 - val_mean_absolute_error: 1.9253\n",
      "Epoch 61/100\n",
      "48948/48948 [==============================] - 259s 5ms/step - loss: 5.5410 - mean_absolute_error: 1.9198 - val_loss: 5.5881 - val_mean_absolute_error: 1.9351\n",
      "Epoch 62/100\n",
      "48948/48948 [==============================] - 280s 6ms/step - loss: 5.5369 - mean_absolute_error: 1.9190 - val_loss: 5.5914 - val_mean_absolute_error: 1.9167\n",
      "Epoch 63/100\n",
      "48948/48948 [==============================] - 259s 5ms/step - loss: 5.5346 - mean_absolute_error: 1.9185 - val_loss: 5.5815 - val_mean_absolute_error: 1.9197\n",
      "Epoch 64/100\n",
      "48948/48948 [==============================] - 257s 5ms/step - loss: 5.5308 - mean_absolute_error: 1.9177 - val_loss: 5.5713 - val_mean_absolute_error: 1.9284\n",
      "Epoch 65/100\n",
      "48948/48948 [==============================] - 269s 5ms/step - loss: 5.5280 - mean_absolute_error: 1.9170 - val_loss: 5.5871 - val_mean_absolute_error: 1.9298\n",
      "Epoch 66/100\n",
      "48948/48948 [==============================] - 262s 5ms/step - loss: 5.5267 - mean_absolute_error: 1.9168 - val_loss: 5.5719 - val_mean_absolute_error: 1.9289\n",
      "Epoch 67/100\n",
      "48948/48948 [==============================] - 252s 5ms/step - loss: 5.5228 - mean_absolute_error: 1.9160 - val_loss: 5.5744 - val_mean_absolute_error: 1.9212\n",
      "Epoch 68/100\n",
      "48948/48948 [==============================] - 250s 5ms/step - loss: 5.5198 - mean_absolute_error: 1.9152 - val_loss: 5.5755 - val_mean_absolute_error: 1.9271\n",
      "Epoch 69/100\n",
      "48948/48948 [==============================] - 257s 5ms/step - loss: 5.5170 - mean_absolute_error: 1.9147 - val_loss: 5.5614 - val_mean_absolute_error: 1.9269\n",
      "Epoch 70/100\n",
      "48948/48948 [==============================] - 273s 6ms/step - loss: 5.5136 - mean_absolute_error: 1.9141 - val_loss: 5.5762 - val_mean_absolute_error: 1.9301\n",
      "Epoch 71/100\n",
      "48948/48948 [==============================] - 273s 6ms/step - loss: 5.5105 - mean_absolute_error: 1.9134 - val_loss: 5.5562 - val_mean_absolute_error: 1.9185\n",
      "Epoch 72/100\n",
      "48948/48948 [==============================] - 259s 5ms/step - loss: 5.5083 - mean_absolute_error: 1.9129 - val_loss: 5.5412 - val_mean_absolute_error: 1.9230\n",
      "Epoch 73/100\n",
      "48948/48948 [==============================] - 248s 5ms/step - loss: 5.5053 - mean_absolute_error: 1.9124 - val_loss: 5.5563 - val_mean_absolute_error: 1.9257\n",
      "Epoch 74/100\n",
      "48948/48948 [==============================] - 246s 5ms/step - loss: 5.5027 - mean_absolute_error: 1.9114 - val_loss: 5.6286 - val_mean_absolute_error: 1.9483\n",
      "Epoch 75/100\n",
      "48948/48948 [==============================] - 244s 5ms/step - loss: 5.4993 - mean_absolute_error: 1.9109 - val_loss: 5.5781 - val_mean_absolute_error: 1.9211\n",
      "Epoch 76/100\n",
      "48948/48948 [==============================] - 246s 5ms/step - loss: 5.4976 - mean_absolute_error: 1.9107 - val_loss: 5.5484 - val_mean_absolute_error: 1.9158\n",
      "Epoch 77/100\n",
      "48948/48948 [==============================] - 240s 5ms/step - loss: 5.4930 - mean_absolute_error: 1.9097 - val_loss: 5.5360 - val_mean_absolute_error: 1.9231\n",
      "Epoch 78/100\n",
      "48948/48948 [==============================] - 244s 5ms/step - loss: 5.4927 - mean_absolute_error: 1.9097 - val_loss: 5.5666 - val_mean_absolute_error: 1.9244\n",
      "Epoch 79/100\n",
      "48948/48948 [==============================] - 244s 5ms/step - loss: 5.4883 - mean_absolute_error: 1.9086 - val_loss: 5.5300 - val_mean_absolute_error: 1.9175\n",
      "Epoch 80/100\n",
      "48948/48948 [==============================] - 246s 5ms/step - loss: 5.4856 - mean_absolute_error: 1.9081 - val_loss: 5.5347 - val_mean_absolute_error: 1.9144\n",
      "Epoch 81/100\n",
      "48948/48948 [==============================] - 245s 5ms/step - loss: 5.4836 - mean_absolute_error: 1.9076 - val_loss: 5.5802 - val_mean_absolute_error: 1.9183\n",
      "Epoch 82/100\n",
      "48948/48948 [==============================] - 247s 5ms/step - loss: 5.4813 - mean_absolute_error: 1.9073 - val_loss: 5.5425 - val_mean_absolute_error: 1.9217\n",
      "Epoch 83/100\n",
      "48948/48948 [==============================] - 240s 5ms/step - loss: 5.4778 - mean_absolute_error: 1.9064 - val_loss: 5.5658 - val_mean_absolute_error: 1.9235\n",
      "Epoch 84/100\n",
      "48948/48948 [==============================] - 233s 5ms/step - loss: 5.4773 - mean_absolute_error: 1.9060 - val_loss: 5.5435 - val_mean_absolute_error: 1.9228\n",
      "Epoch 85/100\n",
      "48948/48948 [==============================] - 238s 5ms/step - loss: 5.4729 - mean_absolute_error: 1.9053 - val_loss: 5.5418 - val_mean_absolute_error: 1.9165\n",
      "Epoch 86/100\n",
      "48948/48948 [==============================] - 240s 5ms/step - loss: 5.4704 - mean_absolute_error: 1.9049 - val_loss: 5.5297 - val_mean_absolute_error: 1.9218\n",
      "Epoch 87/100\n",
      "48948/48948 [==============================] - 238s 5ms/step - loss: 5.4680 - mean_absolute_error: 1.9044 - val_loss: 5.5296 - val_mean_absolute_error: 1.9166\n",
      "Epoch 88/100\n",
      "48948/48948 [==============================] - 240s 5ms/step - loss: 5.4662 - mean_absolute_error: 1.9038 - val_loss: 5.5452 - val_mean_absolute_error: 1.9123\n",
      "Epoch 89/100\n",
      "48948/48948 [==============================] - 235s 5ms/step - loss: 5.4632 - mean_absolute_error: 1.9035 - val_loss: 5.5503 - val_mean_absolute_error: 1.9141\n",
      "Epoch 90/100\n",
      "48948/48948 [==============================] - 238s 5ms/step - loss: 5.4611 - mean_absolute_error: 1.9029 - val_loss: 5.5675 - val_mean_absolute_error: 1.9352\n",
      "Epoch 91/100\n",
      "48948/48948 [==============================] - 236s 5ms/step - loss: 5.4593 - mean_absolute_error: 1.9025 - val_loss: 5.5489 - val_mean_absolute_error: 1.9294\n",
      "Epoch 92/100\n",
      "48948/48948 [==============================] - 235s 5ms/step - loss: 5.4550 - mean_absolute_error: 1.9015 - val_loss: 5.5257 - val_mean_absolute_error: 1.9188\n",
      "Epoch 93/100\n",
      "48948/48948 [==============================] - 233s 5ms/step - loss: 5.4545 - mean_absolute_error: 1.9013 - val_loss: 5.5114 - val_mean_absolute_error: 1.9127\n",
      "Epoch 94/100\n",
      "48948/48948 [==============================] - 239s 5ms/step - loss: 5.4505 - mean_absolute_error: 1.9006 - val_loss: 5.5053 - val_mean_absolute_error: 1.9111\n",
      "Epoch 95/100\n",
      "48948/48948 [==============================] - 244s 5ms/step - loss: 5.4495 - mean_absolute_error: 1.9004 - val_loss: 5.5110 - val_mean_absolute_error: 1.9104\n",
      "Epoch 96/100\n",
      "48948/48948 [==============================] - 236s 5ms/step - loss: 5.4474 - mean_absolute_error: 1.9004 - val_loss: 5.5192 - val_mean_absolute_error: 1.9146\n",
      "Epoch 97/100\n",
      "48948/48948 [==============================] - 237s 5ms/step - loss: 5.4448 - mean_absolute_error: 1.8995 - val_loss: 5.5160 - val_mean_absolute_error: 1.9176\n",
      "Epoch 98/100\n",
      "48948/48948 [==============================] - 239s 5ms/step - loss: 5.4416 - mean_absolute_error: 1.8988 - val_loss: 5.5240 - val_mean_absolute_error: 1.9186\n",
      "Epoch 99/100\n",
      "48948/48948 [==============================] - 236s 5ms/step - loss: 5.4378 - mean_absolute_error: 1.8983 - val_loss: 5.5377 - val_mean_absolute_error: 1.9223\n",
      "Epoch 100/100\n",
      "48948/48948 [==============================] - 235s 5ms/step - loss: 5.4371 - mean_absolute_error: 1.8979 - val_loss: 5.4936 - val_mean_absolute_error: 1.9102\n",
      "12237/12237 [==============================] - 19s 2ms/step - loss: 5.4936 - mean_absolute_error: 1.9102\n",
      "Optimizer: SGD\n",
      "Mean Squared Error on Test Data: 5.49\n",
      "Mean Absolute Error on Test Data: 1.91\n",
      "Epoch 1/100\n",
      "48948/48948 [==============================] - 385s 8ms/step - loss: 6.3183 - mean_absolute_error: 2.0610 - val_loss: 6.0907 - val_mean_absolute_error: 2.0195\n",
      "Epoch 2/100\n",
      "48948/48948 [==============================] - 388s 8ms/step - loss: 6.0727 - mean_absolute_error: 2.0276 - val_loss: 6.0974 - val_mean_absolute_error: 2.0277\n",
      "Epoch 3/100\n",
      "48948/48948 [==============================] - 393s 8ms/step - loss: 6.0315 - mean_absolute_error: 2.0205 - val_loss: 6.0008 - val_mean_absolute_error: 2.0032\n",
      "Epoch 4/100\n",
      "48948/48948 [==============================] - 388s 8ms/step - loss: 5.9954 - mean_absolute_error: 2.0134 - val_loss: 5.9772 - val_mean_absolute_error: 1.9999\n",
      "Epoch 5/100\n",
      "48948/48948 [==============================] - 339s 7ms/step - loss: 5.9588 - mean_absolute_error: 2.0062 - val_loss: 5.9803 - val_mean_absolute_error: 2.0142\n",
      "Epoch 6/100\n",
      "48948/48948 [==============================] - 341s 7ms/step - loss: 5.9354 - mean_absolute_error: 2.0015 - val_loss: 5.9436 - val_mean_absolute_error: 1.9858\n",
      "Epoch 7/100\n",
      "48948/48948 [==============================] - 337s 7ms/step - loss: 5.9187 - mean_absolute_error: 1.9981 - val_loss: 5.9025 - val_mean_absolute_error: 2.0016\n",
      "Epoch 8/100\n",
      "48948/48948 [==============================] - 338s 7ms/step - loss: 5.9012 - mean_absolute_error: 1.9945 - val_loss: 5.8775 - val_mean_absolute_error: 1.9877\n",
      "Epoch 9/100\n",
      "48948/48948 [==============================] - 340s 7ms/step - loss: 5.8868 - mean_absolute_error: 1.9915 - val_loss: 5.8982 - val_mean_absolute_error: 1.9921\n",
      "Epoch 10/100\n",
      "48948/48948 [==============================] - 340s 7ms/step - loss: 5.8765 - mean_absolute_error: 1.9895 - val_loss: 5.8785 - val_mean_absolute_error: 2.0044\n",
      "Epoch 11/100\n",
      "48948/48948 [==============================] - 343s 7ms/step - loss: 5.8629 - mean_absolute_error: 1.9867 - val_loss: 5.8534 - val_mean_absolute_error: 1.9786\n",
      "Epoch 12/100\n",
      "48948/48948 [==============================] - 342s 7ms/step - loss: 5.8523 - mean_absolute_error: 1.9843 - val_loss: 5.8744 - val_mean_absolute_error: 1.9873\n",
      "Epoch 13/100\n",
      "48948/48948 [==============================] - 339s 7ms/step - loss: 5.8429 - mean_absolute_error: 1.9825 - val_loss: 5.8694 - val_mean_absolute_error: 1.9720\n",
      "Epoch 14/100\n",
      "48948/48948 [==============================] - 340s 7ms/step - loss: 5.8367 - mean_absolute_error: 1.9812 - val_loss: 5.8247 - val_mean_absolute_error: 1.9846\n",
      "Epoch 15/100\n",
      "48948/48948 [==============================] - 341s 7ms/step - loss: 5.8293 - mean_absolute_error: 1.9798 - val_loss: 5.8156 - val_mean_absolute_error: 1.9790\n",
      "Epoch 16/100\n",
      "48948/48948 [==============================] - 340s 7ms/step - loss: 5.8225 - mean_absolute_error: 1.9782 - val_loss: 5.8122 - val_mean_absolute_error: 1.9709\n",
      "Epoch 17/100\n",
      "48948/48948 [==============================] - 344s 7ms/step - loss: 5.8159 - mean_absolute_error: 1.9769 - val_loss: 5.8042 - val_mean_absolute_error: 1.9829\n",
      "Epoch 18/100\n",
      "48948/48948 [==============================] - 340s 7ms/step - loss: 5.8094 - mean_absolute_error: 1.9755 - val_loss: 5.8039 - val_mean_absolute_error: 1.9689\n",
      "Epoch 19/100\n",
      "48948/48948 [==============================] - 339s 7ms/step - loss: 5.8044 - mean_absolute_error: 1.9745 - val_loss: 5.8177 - val_mean_absolute_error: 1.9838\n",
      "Epoch 20/100\n",
      "48948/48948 [==============================] - 339s 7ms/step - loss: 5.7999 - mean_absolute_error: 1.9737 - val_loss: 5.8073 - val_mean_absolute_error: 1.9875\n",
      "Epoch 21/100\n",
      "48948/48948 [==============================] - 338s 7ms/step - loss: 5.7954 - mean_absolute_error: 1.9729 - val_loss: 5.7898 - val_mean_absolute_error: 1.9727\n",
      "Epoch 22/100\n",
      "48948/48948 [==============================] - 340s 7ms/step - loss: 5.7920 - mean_absolute_error: 1.9721 - val_loss: 5.7954 - val_mean_absolute_error: 1.9646\n",
      "Epoch 23/100\n",
      "48948/48948 [==============================] - 341s 7ms/step - loss: 5.7868 - mean_absolute_error: 1.9709 - val_loss: 5.7921 - val_mean_absolute_error: 1.9707\n",
      "Epoch 24/100\n",
      "48948/48948 [==============================] - 338s 7ms/step - loss: 5.7826 - mean_absolute_error: 1.9701 - val_loss: 5.7961 - val_mean_absolute_error: 1.9921\n",
      "Epoch 25/100\n",
      "48948/48948 [==============================] - 340s 7ms/step - loss: 5.7770 - mean_absolute_error: 1.9690 - val_loss: 5.7924 - val_mean_absolute_error: 1.9862\n",
      "Epoch 26/100\n",
      "48948/48948 [==============================] - 340s 7ms/step - loss: 5.7729 - mean_absolute_error: 1.9681 - val_loss: 5.7887 - val_mean_absolute_error: 1.9702\n",
      "Epoch 27/100\n",
      "48948/48948 [==============================] - 339s 7ms/step - loss: 5.7707 - mean_absolute_error: 1.9676 - val_loss: 5.8268 - val_mean_absolute_error: 1.9842\n",
      "Epoch 28/100\n",
      "48948/48948 [==============================] - 338s 7ms/step - loss: 5.7685 - mean_absolute_error: 1.9671 - val_loss: 5.7780 - val_mean_absolute_error: 1.9837\n",
      "Epoch 29/100\n",
      "48948/48948 [==============================] - 341s 7ms/step - loss: 5.7633 - mean_absolute_error: 1.9661 - val_loss: 5.7543 - val_mean_absolute_error: 1.9646\n",
      "Epoch 30/100\n",
      "48948/48948 [==============================] - 341s 7ms/step - loss: 5.7608 - mean_absolute_error: 1.9655 - val_loss: 5.7766 - val_mean_absolute_error: 1.9662\n",
      "Epoch 31/100\n",
      "48948/48948 [==============================] - 340s 7ms/step - loss: 5.7574 - mean_absolute_error: 1.9650 - val_loss: 5.7591 - val_mean_absolute_error: 1.9600\n",
      "Epoch 32/100\n",
      "48948/48948 [==============================] - 341s 7ms/step - loss: 5.7550 - mean_absolute_error: 1.9646 - val_loss: 5.7671 - val_mean_absolute_error: 1.9828\n",
      "Epoch 33/100\n",
      "48948/48948 [==============================] - 341s 7ms/step - loss: 5.7520 - mean_absolute_error: 1.9639 - val_loss: 5.7482 - val_mean_absolute_error: 1.9588\n",
      "Epoch 34/100\n",
      "48948/48948 [==============================] - 339s 7ms/step - loss: 5.7497 - mean_absolute_error: 1.9635 - val_loss: 5.7738 - val_mean_absolute_error: 1.9498\n",
      "Epoch 35/100\n",
      "48948/48948 [==============================] - 337s 7ms/step - loss: 5.7475 - mean_absolute_error: 1.9631 - val_loss: 5.7559 - val_mean_absolute_error: 1.9688\n",
      "Epoch 36/100\n",
      "48948/48948 [==============================] - 336s 7ms/step - loss: 5.7458 - mean_absolute_error: 1.9628 - val_loss: 5.7479 - val_mean_absolute_error: 1.9681\n",
      "Epoch 37/100\n",
      "48948/48948 [==============================] - 338s 7ms/step - loss: 5.7428 - mean_absolute_error: 1.9620 - val_loss: 5.7665 - val_mean_absolute_error: 1.9530\n",
      "Epoch 38/100\n",
      "48948/48948 [==============================] - 341s 7ms/step - loss: 5.7425 - mean_absolute_error: 1.9620 - val_loss: 5.7606 - val_mean_absolute_error: 1.9744\n",
      "Epoch 39/100\n",
      "48948/48948 [==============================] - 342s 7ms/step - loss: 5.7397 - mean_absolute_error: 1.9615 - val_loss: 5.7609 - val_mean_absolute_error: 1.9792\n",
      "Epoch 40/100\n",
      "48948/48948 [==============================] - 339s 7ms/step - loss: 5.7378 - mean_absolute_error: 1.9610 - val_loss: 5.7388 - val_mean_absolute_error: 1.9704\n",
      "Epoch 41/100\n",
      "48948/48948 [==============================] - 340s 7ms/step - loss: 5.7358 - mean_absolute_error: 1.9606 - val_loss: 5.7378 - val_mean_absolute_error: 1.9518\n",
      "Epoch 42/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48948/48948 [==============================] - 341s 7ms/step - loss: 5.7343 - mean_absolute_error: 1.9603 - val_loss: 5.7421 - val_mean_absolute_error: 1.9764\n",
      "Epoch 43/100\n",
      "48948/48948 [==============================] - 320s 7ms/step - loss: 5.7332 - mean_absolute_error: 1.9599 - val_loss: 5.7515 - val_mean_absolute_error: 1.9611\n",
      "Epoch 44/100\n",
      "48948/48948 [==============================] - 322s 7ms/step - loss: 5.7325 - mean_absolute_error: 1.9599 - val_loss: 5.7562 - val_mean_absolute_error: 1.9798\n",
      "Epoch 45/100\n",
      "48948/48948 [==============================] - 330s 7ms/step - loss: 5.7317 - mean_absolute_error: 1.9597 - val_loss: 5.7317 - val_mean_absolute_error: 1.9538\n",
      "Epoch 46/100\n",
      "48948/48948 [==============================] - 331s 7ms/step - loss: 5.7298 - mean_absolute_error: 1.9593 - val_loss: 5.7229 - val_mean_absolute_error: 1.9603\n",
      "Epoch 47/100\n",
      "48948/48948 [==============================] - 329s 7ms/step - loss: 5.7267 - mean_absolute_error: 1.9586 - val_loss: 5.7308 - val_mean_absolute_error: 1.9645\n",
      "Epoch 48/100\n",
      "48948/48948 [==============================] - 329s 7ms/step - loss: 5.7269 - mean_absolute_error: 1.9588 - val_loss: 5.7333 - val_mean_absolute_error: 1.9566\n",
      "Epoch 49/100\n",
      "48948/48948 [==============================] - 327s 7ms/step - loss: 5.7229 - mean_absolute_error: 1.9580 - val_loss: 5.7371 - val_mean_absolute_error: 1.9570\n",
      "Epoch 50/100\n",
      "48948/48948 [==============================] - 328s 7ms/step - loss: 5.7223 - mean_absolute_error: 1.9579 - val_loss: 5.7229 - val_mean_absolute_error: 1.9606\n",
      "Epoch 51/100\n",
      "48948/48948 [==============================] - 327s 7ms/step - loss: 5.7202 - mean_absolute_error: 1.9573 - val_loss: 5.7739 - val_mean_absolute_error: 1.9622\n",
      "Epoch 52/100\n",
      "48948/48948 [==============================] - 331s 7ms/step - loss: 5.7207 - mean_absolute_error: 1.9574 - val_loss: 5.8163 - val_mean_absolute_error: 1.9873\n",
      "Epoch 53/100\n",
      "48948/48948 [==============================] - 330s 7ms/step - loss: 5.7194 - mean_absolute_error: 1.9573 - val_loss: 5.7326 - val_mean_absolute_error: 1.9702\n",
      "Epoch 54/100\n",
      "48948/48948 [==============================] - 333s 7ms/step - loss: 5.7167 - mean_absolute_error: 1.9568 - val_loss: 5.7129 - val_mean_absolute_error: 1.9521\n",
      "Epoch 55/100\n",
      "48948/48948 [==============================] - 332s 7ms/step - loss: 5.7148 - mean_absolute_error: 1.9562 - val_loss: 5.7240 - val_mean_absolute_error: 1.9494\n",
      "Epoch 56/100\n",
      "48948/48948 [==============================] - 332s 7ms/step - loss: 5.7126 - mean_absolute_error: 1.9556 - val_loss: 5.7220 - val_mean_absolute_error: 1.9411\n",
      "Epoch 57/100\n",
      "48948/48948 [==============================] - 332s 7ms/step - loss: 5.7103 - mean_absolute_error: 1.9554 - val_loss: 5.7367 - val_mean_absolute_error: 1.9467\n",
      "Epoch 58/100\n",
      "48948/48948 [==============================] - 330s 7ms/step - loss: 5.7106 - mean_absolute_error: 1.9553 - val_loss: 5.7187 - val_mean_absolute_error: 1.9499\n",
      "Epoch 59/100\n",
      "48948/48948 [==============================] - 339s 7ms/step - loss: 5.7109 - mean_absolute_error: 1.9552 - val_loss: 5.7337 - val_mean_absolute_error: 1.9732\n",
      "Epoch 60/100\n",
      "48948/48948 [==============================] - 340s 7ms/step - loss: 5.7107 - mean_absolute_error: 1.9553 - val_loss: 5.7110 - val_mean_absolute_error: 1.9642\n",
      "Epoch 61/100\n",
      "48948/48948 [==============================] - 339s 7ms/step - loss: 5.7076 - mean_absolute_error: 1.9548 - val_loss: 5.7264 - val_mean_absolute_error: 1.9512\n",
      "Epoch 62/100\n",
      "48948/48948 [==============================] - 339s 7ms/step - loss: 5.7072 - mean_absolute_error: 1.9546 - val_loss: 5.7699 - val_mean_absolute_error: 1.9683\n",
      "Epoch 63/100\n",
      "48948/48948 [==============================] - 341s 7ms/step - loss: 5.7077 - mean_absolute_error: 1.9548 - val_loss: 5.7079 - val_mean_absolute_error: 1.9528\n",
      "Epoch 64/100\n",
      "48948/48948 [==============================] - 337s 7ms/step - loss: 5.7058 - mean_absolute_error: 1.9544 - val_loss: 5.7130 - val_mean_absolute_error: 1.9513\n",
      "Epoch 65/100\n",
      "48948/48948 [==============================] - 353s 7ms/step - loss: 5.7065 - mean_absolute_error: 1.9546 - val_loss: 5.7225 - val_mean_absolute_error: 1.9514\n",
      "Epoch 66/100\n",
      "48948/48948 [==============================] - 341s 7ms/step - loss: 5.7061 - mean_absolute_error: 1.9546 - val_loss: 5.7046 - val_mean_absolute_error: 1.9612\n",
      "Epoch 67/100\n",
      "48948/48948 [==============================] - 346s 7ms/step - loss: 5.7031 - mean_absolute_error: 1.9539 - val_loss: 5.7116 - val_mean_absolute_error: 1.9467\n",
      "Epoch 68/100\n",
      "48948/48948 [==============================] - 341s 7ms/step - loss: 5.7012 - mean_absolute_error: 1.9535 - val_loss: 5.7180 - val_mean_absolute_error: 1.9427\n",
      "Epoch 69/100\n",
      "48948/48948 [==============================] - 357s 7ms/step - loss: 5.7007 - mean_absolute_error: 1.9535 - val_loss: 5.7277 - val_mean_absolute_error: 1.9483\n",
      "Epoch 70/100\n",
      "48948/48948 [==============================] - 344s 7ms/step - loss: 5.6988 - mean_absolute_error: 1.9528 - val_loss: 5.7034 - val_mean_absolute_error: 1.9422\n",
      "Epoch 71/100\n",
      "48948/48948 [==============================] - 343s 7ms/step - loss: 5.6984 - mean_absolute_error: 1.9529 - val_loss: 5.7013 - val_mean_absolute_error: 1.9462\n",
      "Epoch 72/100\n",
      "48948/48948 [==============================] - 352s 7ms/step - loss: 5.6964 - mean_absolute_error: 1.9525 - val_loss: 5.7158 - val_mean_absolute_error: 1.9577\n",
      "Epoch 73/100\n",
      "48948/48948 [==============================] - 358s 7ms/step - loss: 5.6959 - mean_absolute_error: 1.9526 - val_loss: 5.7033 - val_mean_absolute_error: 1.9608\n",
      "Epoch 74/100\n",
      "48948/48948 [==============================] - 356s 7ms/step - loss: 5.6947 - mean_absolute_error: 1.9522 - val_loss: 5.6919 - val_mean_absolute_error: 1.9491\n",
      "Epoch 75/100\n",
      "48948/48948 [==============================] - 359s 7ms/step - loss: 5.6921 - mean_absolute_error: 1.9517 - val_loss: 5.7804 - val_mean_absolute_error: 1.9366\n",
      "Epoch 76/100\n",
      "48948/48948 [==============================] - 356s 7ms/step - loss: 5.6930 - mean_absolute_error: 1.9518 - val_loss: 5.7033 - val_mean_absolute_error: 1.9646\n",
      "Epoch 77/100\n",
      "48948/48948 [==============================] - 349s 7ms/step - loss: 5.6924 - mean_absolute_error: 1.9518 - val_loss: 5.7143 - val_mean_absolute_error: 1.9654\n",
      "Epoch 78/100\n",
      "48948/48948 [==============================] - 339s 7ms/step - loss: 5.6920 - mean_absolute_error: 1.9518 - val_loss: 5.7023 - val_mean_absolute_error: 1.9452\n",
      "Epoch 79/100\n",
      "48948/48948 [==============================] - 351s 7ms/step - loss: 5.6886 - mean_absolute_error: 1.9510 - val_loss: 5.7044 - val_mean_absolute_error: 1.9640\n",
      "Epoch 80/100\n",
      "48948/48948 [==============================] - 358s 7ms/step - loss: 5.6886 - mean_absolute_error: 1.9508 - val_loss: 5.6896 - val_mean_absolute_error: 1.9562\n",
      "Epoch 81/100\n",
      "48948/48948 [==============================] - 360s 7ms/step - loss: 5.6882 - mean_absolute_error: 1.9509 - val_loss: 5.7163 - val_mean_absolute_error: 1.9526\n",
      "Epoch 82/100\n",
      "48948/48948 [==============================] - 362s 7ms/step - loss: 5.6858 - mean_absolute_error: 1.9502 - val_loss: 5.7062 - val_mean_absolute_error: 1.9532\n",
      "Epoch 83/100\n",
      "48948/48948 [==============================] - 362s 7ms/step - loss: 5.6854 - mean_absolute_error: 1.9501 - val_loss: 5.6894 - val_mean_absolute_error: 1.9516\n",
      "Epoch 84/100\n",
      "48948/48948 [==============================] - 359s 7ms/step - loss: 5.6842 - mean_absolute_error: 1.9501 - val_loss: 5.7008 - val_mean_absolute_error: 1.9535\n",
      "Epoch 85/100\n",
      "48948/48948 [==============================] - 358s 7ms/step - loss: 5.6817 - mean_absolute_error: 1.9497 - val_loss: 5.7159 - val_mean_absolute_error: 1.9664\n",
      "Epoch 86/100\n",
      "48948/48948 [==============================] - 357s 7ms/step - loss: 5.6816 - mean_absolute_error: 1.9495 - val_loss: 5.6985 - val_mean_absolute_error: 1.9559\n",
      "Epoch 87/100\n",
      "48948/48948 [==============================] - 361s 7ms/step - loss: 5.6801 - mean_absolute_error: 1.9492 - val_loss: 5.7021 - val_mean_absolute_error: 1.9452\n",
      "Epoch 88/100\n",
      "48948/48948 [==============================] - 358s 7ms/step - loss: 5.6790 - mean_absolute_error: 1.9490 - val_loss: 5.6828 - val_mean_absolute_error: 1.9493\n",
      "Epoch 89/100\n",
      "48948/48948 [==============================] - 355s 7ms/step - loss: 5.6774 - mean_absolute_error: 1.9488 - val_loss: 5.6988 - val_mean_absolute_error: 1.9442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 90/100\n",
      "48948/48948 [==============================] - 355s 7ms/step - loss: 5.6798 - mean_absolute_error: 1.9492 - val_loss: 5.6868 - val_mean_absolute_error: 1.9566\n",
      "Epoch 91/100\n",
      "48948/48948 [==============================] - 354s 7ms/step - loss: 5.6786 - mean_absolute_error: 1.9490 - val_loss: 5.6972 - val_mean_absolute_error: 1.9604\n",
      "Epoch 92/100\n",
      "48948/48948 [==============================] - 352s 7ms/step - loss: 5.6765 - mean_absolute_error: 1.9485 - val_loss: 5.6858 - val_mean_absolute_error: 1.9569\n",
      "Epoch 93/100\n",
      "48948/48948 [==============================] - 366s 7ms/step - loss: 5.6748 - mean_absolute_error: 1.9482 - val_loss: 5.6858 - val_mean_absolute_error: 1.9506\n",
      "Epoch 94/100\n",
      "48948/48948 [==============================] - 357s 7ms/step - loss: 5.6727 - mean_absolute_error: 1.9477 - val_loss: 5.6869 - val_mean_absolute_error: 1.9556\n",
      "Epoch 95/100\n",
      "48948/48948 [==============================] - 345s 7ms/step - loss: 5.6719 - mean_absolute_error: 1.9476 - val_loss: 5.6892 - val_mean_absolute_error: 1.9551\n",
      "Epoch 96/100\n",
      "48948/48948 [==============================] - 362s 7ms/step - loss: 5.6718 - mean_absolute_error: 1.9476 - val_loss: 5.6889 - val_mean_absolute_error: 1.9404\n",
      "Epoch 97/100\n",
      "48948/48948 [==============================] - 384s 8ms/step - loss: 5.6700 - mean_absolute_error: 1.9470 - val_loss: 5.6780 - val_mean_absolute_error: 1.9477\n",
      "Epoch 98/100\n",
      "48948/48948 [==============================] - 356s 7ms/step - loss: 5.6689 - mean_absolute_error: 1.9469 - val_loss: 5.6975 - val_mean_absolute_error: 1.9622\n",
      "Epoch 99/100\n",
      "48948/48948 [==============================] - 357s 7ms/step - loss: 5.6690 - mean_absolute_error: 1.9470 - val_loss: 5.6847 - val_mean_absolute_error: 1.9610\n",
      "Epoch 100/100\n",
      "48948/48948 [==============================] - 355s 7ms/step - loss: 5.6682 - mean_absolute_error: 1.9467 - val_loss: 5.6838 - val_mean_absolute_error: 1.9530\n",
      "12237/12237 [==============================] - 18s 1ms/step - loss: 5.6838 - mean_absolute_error: 1.9530\n",
      "Optimizer: Adam\n",
      "Mean Squared Error on Test Data: 5.68\n",
      "Mean Absolute Error on Test Data: 1.95\n",
      "Epoch 1/100\n",
      "48948/48948 [==============================] - 294s 6ms/step - loss: 6.3472 - mean_absolute_error: 2.0657 - val_loss: 6.0817 - val_mean_absolute_error: 2.0050\n",
      "Epoch 2/100\n",
      "48948/48948 [==============================] - 295s 6ms/step - loss: 6.0703 - mean_absolute_error: 2.0269 - val_loss: 6.0568 - val_mean_absolute_error: 2.0059\n",
      "Epoch 3/100\n",
      "48948/48948 [==============================] - 297s 6ms/step - loss: 6.0463 - mean_absolute_error: 2.0224 - val_loss: 6.1103 - val_mean_absolute_error: 2.0104\n",
      "Epoch 4/100\n",
      "48948/48948 [==============================] - 292s 6ms/step - loss: 6.0310 - mean_absolute_error: 2.0191 - val_loss: 6.0028 - val_mean_absolute_error: 2.0028\n",
      "Epoch 5/100\n",
      "48948/48948 [==============================] - 288s 6ms/step - loss: 6.0209 - mean_absolute_error: 2.0178 - val_loss: 6.0329 - val_mean_absolute_error: 2.0011\n",
      "Epoch 6/100\n",
      "48948/48948 [==============================] - 299s 6ms/step - loss: 6.0112 - mean_absolute_error: 2.0163 - val_loss: 5.9830 - val_mean_absolute_error: 2.0047\n",
      "Epoch 7/100\n",
      "48948/48948 [==============================] - 298s 6ms/step - loss: 6.0078 - mean_absolute_error: 2.0155 - val_loss: 5.9928 - val_mean_absolute_error: 2.0144\n",
      "Epoch 8/100\n",
      "48948/48948 [==============================] - 301s 6ms/step - loss: 6.0032 - mean_absolute_error: 2.0146 - val_loss: 5.9773 - val_mean_absolute_error: 2.0207\n",
      "Epoch 9/100\n",
      "48948/48948 [==============================] - 294s 6ms/step - loss: 6.0028 - mean_absolute_error: 2.0143 - val_loss: 6.0012 - val_mean_absolute_error: 2.0279\n",
      "Epoch 10/100\n",
      "48948/48948 [==============================] - 288s 6ms/step - loss: 6.0029 - mean_absolute_error: 2.0145 - val_loss: 5.9787 - val_mean_absolute_error: 2.0120\n",
      "Epoch 11/100\n",
      "48948/48948 [==============================] - 292s 6ms/step - loss: 6.0002 - mean_absolute_error: 2.0137 - val_loss: 5.9757 - val_mean_absolute_error: 2.0175\n",
      "Epoch 12/100\n",
      "48948/48948 [==============================] - 292s 6ms/step - loss: 5.9951 - mean_absolute_error: 2.0125 - val_loss: 6.0082 - val_mean_absolute_error: 1.9954\n",
      "Epoch 13/100\n",
      "48948/48948 [==============================] - 294s 6ms/step - loss: 5.9940 - mean_absolute_error: 2.0125 - val_loss: 5.9914 - val_mean_absolute_error: 2.0073\n",
      "Epoch 14/100\n",
      "48948/48948 [==============================] - 294s 6ms/step - loss: 5.9910 - mean_absolute_error: 2.0123 - val_loss: 5.9775 - val_mean_absolute_error: 2.0022\n",
      "Epoch 15/100\n",
      "48948/48948 [==============================] - 290s 6ms/step - loss: 5.9810 - mean_absolute_error: 2.0104 - val_loss: 5.9784 - val_mean_absolute_error: 2.0033\n",
      "Epoch 16/100\n",
      "48948/48948 [==============================] - 288s 6ms/step - loss: 5.9781 - mean_absolute_error: 2.0097 - val_loss: 5.9946 - val_mean_absolute_error: 2.0279\n",
      "Epoch 17/100\n",
      "48948/48948 [==============================] - 288s 6ms/step - loss: 5.9794 - mean_absolute_error: 2.0098 - val_loss: 5.9548 - val_mean_absolute_error: 2.0176\n",
      "Epoch 18/100\n",
      "48948/48948 [==============================] - 284s 6ms/step - loss: 5.9759 - mean_absolute_error: 2.0089 - val_loss: 5.9783 - val_mean_absolute_error: 2.0111\n",
      "Epoch 19/100\n",
      "48948/48948 [==============================] - 285s 6ms/step - loss: 5.9770 - mean_absolute_error: 2.0089 - val_loss: 5.9614 - val_mean_absolute_error: 2.0074\n",
      "Epoch 20/100\n",
      "48948/48948 [==============================] - 312s 6ms/step - loss: 5.9752 - mean_absolute_error: 2.0085 - val_loss: 6.0157 - val_mean_absolute_error: 2.0109\n",
      "Epoch 21/100\n",
      "48948/48948 [==============================] - 301s 6ms/step - loss: 5.9722 - mean_absolute_error: 2.0078 - val_loss: 5.9637 - val_mean_absolute_error: 2.0100\n",
      "Epoch 22/100\n",
      "48948/48948 [==============================] - 306s 6ms/step - loss: 5.9679 - mean_absolute_error: 2.0077 - val_loss: 5.9605 - val_mean_absolute_error: 1.9984\n",
      "Epoch 23/100\n",
      "48948/48948 [==============================] - 306s 6ms/step - loss: 5.9622 - mean_absolute_error: 2.0066 - val_loss: 5.9719 - val_mean_absolute_error: 2.0300\n",
      "Epoch 24/100\n",
      "48948/48948 [==============================] - 301s 6ms/step - loss: 5.9636 - mean_absolute_error: 2.0068 - val_loss: 5.9398 - val_mean_absolute_error: 2.0098\n",
      "Epoch 25/100\n",
      "48948/48948 [==============================] - 307s 6ms/step - loss: 5.9615 - mean_absolute_error: 2.0063 - val_loss: 5.9565 - val_mean_absolute_error: 2.0096\n",
      "Epoch 26/100\n",
      "48948/48948 [==============================] - 299s 6ms/step - loss: 5.9646 - mean_absolute_error: 2.0068 - val_loss: 5.9689 - val_mean_absolute_error: 2.0203\n",
      "Epoch 27/100\n",
      "48948/48948 [==============================] - 294s 6ms/step - loss: 5.9604 - mean_absolute_error: 2.0062 - val_loss: 5.9552 - val_mean_absolute_error: 2.0014\n",
      "Epoch 28/100\n",
      "48948/48948 [==============================] - 296s 6ms/step - loss: 5.9605 - mean_absolute_error: 2.0061 - val_loss: 5.9363 - val_mean_absolute_error: 1.9974\n",
      "Epoch 29/100\n",
      "48948/48948 [==============================] - 303s 6ms/step - loss: 5.9581 - mean_absolute_error: 2.0057 - val_loss: 5.9340 - val_mean_absolute_error: 2.0015\n",
      "Epoch 30/100\n",
      "48948/48948 [==============================] - 306s 6ms/step - loss: 5.9527 - mean_absolute_error: 2.0047 - val_loss: 6.0406 - val_mean_absolute_error: 2.0111\n",
      "Epoch 31/100\n",
      "48948/48948 [==============================] - 299s 6ms/step - loss: 5.9568 - mean_absolute_error: 2.0053 - val_loss: 5.9441 - val_mean_absolute_error: 2.0096\n",
      "Epoch 32/100\n",
      "48948/48948 [==============================] - 306s 6ms/step - loss: 5.9504 - mean_absolute_error: 2.0038 - val_loss: 6.0480 - val_mean_absolute_error: 2.0247\n",
      "Epoch 33/100\n",
      "48948/48948 [==============================] - 305s 6ms/step - loss: 5.9482 - mean_absolute_error: 2.0034 - val_loss: 6.0028 - val_mean_absolute_error: 2.0398\n",
      "Epoch 34/100\n",
      "48948/48948 [==============================] - 306s 6ms/step - loss: 5.9450 - mean_absolute_error: 2.0024 - val_loss: 6.0012 - val_mean_absolute_error: 1.9903\n",
      "Epoch 35/100\n",
      "48948/48948 [==============================] - 309s 6ms/step - loss: 5.9460 - mean_absolute_error: 2.0018 - val_loss: 6.0888 - val_mean_absolute_error: 2.0267\n",
      "Epoch 36/100\n",
      "48948/48948 [==============================] - 309s 6ms/step - loss: 5.9627 - mean_absolute_error: 2.0081 - val_loss: 5.9661 - val_mean_absolute_error: 2.0166\n",
      "Epoch 37/100\n",
      "48948/48948 [==============================] - 309s 6ms/step - loss: 5.9713 - mean_absolute_error: 2.0103 - val_loss: 5.9623 - val_mean_absolute_error: 2.0058\n",
      "Epoch 38/100\n",
      "48948/48948 [==============================] - 304s 6ms/step - loss: 5.9728 - mean_absolute_error: 2.0107 - val_loss: 5.9560 - val_mean_absolute_error: 2.0069\n",
      "Epoch 39/100\n",
      "48948/48948 [==============================] - 307s 6ms/step - loss: 5.9826 - mean_absolute_error: 2.0126 - val_loss: 6.0573 - val_mean_absolute_error: 2.0270\n",
      "Epoch 39: early stopping\n",
      "12237/12237 [==============================] - 20s 2ms/step - loss: 6.0573 - mean_absolute_error: 2.0270\n",
      "Optimizer: RMSprop\n",
      "Mean Squared Error on Test Data: 6.06\n",
      "Mean Absolute Error on Test Data: 2.03\n",
      "Training stopped early at epoch 38 to prevent overfitting.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import SGD, Adam, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Standardize your input features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "optimizers = [SGD(learning_rate=0.001), Adam(learning_rate=0.001), RMSprop(learning_rate=0.001)]\n",
    "\n",
    "# Define the early stopping criteria\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "\n",
    "for optimizer in optimizers:\n",
    "    # Create a Sequential model\n",
    "    model = Sequential([\n",
    "                Dense(1024, activation='relu', input_dim=X_train.shape[1]),\n",
    "                Dense(512, activation='relu'),\n",
    "                Dense(256, activation='relu'),\n",
    "                Dense(128, activation='relu'),\n",
    "                Dense(64, activation='relu'),\n",
    "                Dense(1)\n",
    "            ])\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mean_absolute_error'])\n",
    "\n",
    "    # Train the model with early stopping callback\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=100, batch_size=32, callbacks=[early_stopping])\n",
    "\n",
    "    # Evaluate the model on the test data\n",
    "    loss, mae = model.evaluate(X_test, y_test)\n",
    "    print(f\"Optimizer: {optimizer.get_config()['name']}\")\n",
    "    print(f\"Mean Squared Error on Test Data: {loss:.2f}\")\n",
    "    print(f\"Mean Absolute Error on Test Data: {mae:.2f}\")\n",
    "\n",
    "    if early_stopping.stopped_epoch > 0:\n",
    "        print(f\"Training stopped early at epoch {early_stopping.stopped_epoch} to prevent overfitting.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1933290",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
